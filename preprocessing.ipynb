{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__1Nxb4gRIeN"
   },
   "source": [
    "Done so far :\n",
    "\n",
    "\n",
    "*   Lemmatization\n",
    "*   Stop Words Removal\n",
    "\n",
    "Verify :\n",
    "\n",
    "* Normalization - removing accents, etc.\n",
    "* Dates replaced with strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qZ-TMc9SVHl"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import wordninja \n",
    "\n",
    "####### After importing nltk, run the following only once ######\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "### pip install wordninja ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LpQkEVQOSVHr"
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag=nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict={\"J\": wordnet.ADJ, \n",
    "              \"N\": wordnet.NOUN,\n",
    "              \"V\": wordnet.VERB,\n",
    "              \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n",
    "\n",
    "def lemma_stop(str):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # sentence=arr[0][4]\n",
    "    tokenizer = RegexpTokenizer('\\w+|\\$]\\d\\[+|\\S+,-')\n",
    "    tokenized = tokenizer.tokenize(str)\n",
    "    lemmatized = [lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in tokenized]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in lemmatized if w.lower() not in stop_words]\n",
    "    after_lemma_stop = ' '.join(w for w in filtered_sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PvIwQ6ySVHv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data.npy\n",
    "# data.npy is a 2D array containing the dataset information as\n",
    "# data[i][0] : docID of ith document\n",
    "# data[i][1] : title of ith document\n",
    "# data[i][4] : content of ith document\n",
    "\n",
    "data = np.load('data.npy',allow_pickle = True)\n",
    "# sentence = data[0][4]\n",
    "# print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6aQ7ZcPCH4d",
    "outputId": "8fc93dc4-51e3-48ff-fa64-d5bbef5847a9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204135\n"
     ]
    }
   ],
   "source": [
    "# creating a map {index_in_data_npy, docID}\n",
    "\n",
    "# ex. if ith element in data has docID j,\n",
    "# get_docID[i] will return j\n",
    "\n",
    "get_docID = {}\n",
    "get_index = {}\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "for i in range(0, len(data)) :\n",
    "    get_docID[i] = int(data[i][0])\n",
    "    get_index[int(data[i][0])] = i\n",
    "    # print(get_docID[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_credible (text):\n",
    "    match = re.search(r'[!@#?&{}()]', text)\n",
    "    \n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_words(text):\n",
    "    text = re.sub('[!@#?&{}()]', '', text)\n",
    "    text=re.sub(r'[^\\x00-\\x7F]',\" \",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document (document_string):\n",
    "    cleaned_doc = document_string\n",
    "    for word in document_string.split():\n",
    "                if is_not_credible(word):\n",
    "                    temp= scrub_words(word)\n",
    "                    split=wordninja.split(temp)\n",
    "                    if len(split)>7:\n",
    "                          cleaned_doc = cleaned_doc.replace(word,'')\n",
    "    return cleaned_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def replace_dates(documentString):\n",
    "    \n",
    "    regEx = '(([0-9]+(/|\\\\.|-)[0-9]+(/|\\\\.|-)[0-9]+)|([0-9]+(/|\\\\.|-)[0-9]+))'\n",
    "    iterator = re.finditer(regEx, documentString)\n",
    "    listOfDates = [(m.start(0), m.end(0)) for m in iterator]\n",
    "    \n",
    "    for indices in listOfDates:\n",
    "        date = documentString[indices[0]:indices[1]]\n",
    "        tmp = date\n",
    "        date = date.replace('.', '/')\n",
    "        date = date.replace('-', '/')\n",
    "        count = date.count('/')\n",
    "        newDate = ''\n",
    "        if count == 2:\n",
    "            try:\n",
    "                newDate = datetime.strptime(date, '%m/%d/%Y').strftime('%d %b %Y')\n",
    "            except ValueError as ve:\n",
    "                newDate = date\n",
    "        else:\n",
    "            try:\n",
    "                newDate = datetime.strptime(date, '%m/%d').strftime('%d %b')\n",
    "            except ValueError as ve:\n",
    "                newDate = date\n",
    "                \n",
    "        newDate = newDate.replace(' ', '')\n",
    "        documentString = documentString.replace(tmp, newDate)\n",
    "        # print(newDate)\n",
    "    \n",
    "    return documentString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n",
      "['know', 'States', 'impose', 'reasonable', 'limitation', 'less', 'gun', 'crime', 'less', 'homicide', 'Sen', 'Chris', 'Murphy', 'Conn', 'speak', 'Senate', 'floor', 'June', '15', 'Readers', 'ask', 'fact', 'check', 'gun', 'rhetoric', 'use', 'Democrats', 'wake', 'mass', 'shoot', 'Orlando', 'one', 'case', 'already', 'delve', 'material', 'claim', 'new', 'let', 'take', 'look', 'start', 'Murphy', 'statement', 'Facts', 'Murphy', 'staff', 'say', 'refer', 'chart', 'appear', 'National', 'Journal', '2015', 'turn', 'carefully', 'checked', 'chart', 'President', 'Obama', 'make', 'similar', 'carefully', 'phrase', 'claim', 'gun', 'death', 'Note', 'Murphy', 'refer', 'homicide', 'gun', 'crime', 'President', 'Obama', 'earn', 'Two', 'Pinocchios', 'Readers', 'check', 'full', 'fact', 'check', 'summary', 'note', 'gun', 'death', '60', 'percent', '2013', 'actually', 'suicide', 'data', 'use', 'National', 'Journal', 'chart', 'calculates', 'number', 'gun', 'related', 'death', 'per', '100', '000', 'people', 'include', 'gun', 'death', 'include', 'homicide', 'suicide', 'accidental', 'gun', 'death', 'legal', 'intervention', 'involve', 'firearm', 'remove', 'suicide', 'total', 'reran', 'number', 'case', 'make', 'huge', 'difference', 'Half', '10', 'state', 'low', 'gun', 'death', 'rate', 'turn', 'state', 'less', 'restrictive', 'gun', 'law', 'Moreover', 'counting', 'gun', 'law', 'certainly', 'open', 'interpretation', 'also', 'affect', 'outcome', 'enough', 'count', 'law', 'figure', 'reason', 'gun', 'death', 'low', 'one', 'state', 'another', 'One', 'would', 'need', 'specifically', 'determine', 'whether', 'certain', 'law', 'effect', 'time', 'gun', 'death', 'rate', 'state', 'instance', 'Murphy', 'claim', 'worthy', 'Three', 'Pinocchios', 'specifically', 'refer', 'homicide', 'rather', 'gun', 'death', 'Three', 'Pinocchios', 'rating', 'scale', 'var', 'urlRegex', 'b', 'http', 'Z0', '9', '_', 'Z0', '9', '_', 'ig', 'endPointString', 'Map', 'pattern', 'x3e', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'poll', 'washingtonpost', 'com', 'userpolls', 'game', 'webapi', 'poll', 'id', 'id', 'x3e', 'poll', 'content', 'x3e', 'Simple', 'Id', 'Content', 'Config', 'WPGames', 'WPGames', 'WPGames', 'common', 'WPGames', 'common', 'WPGames', 'common', 'api', 'WPGames', 'common', 'api', 'WPGames', 'common', 'api', 'e68a3044', 'a988', '45a6', 'b59f', 'c346e82d664c', 'endPointString', 'match', 'urlRegex', '0', 'replace', 'poll', 'var', 'shareURL', 'encodeURIComponent', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'wapo', 'st', '21pk0d8', 'window', 'interactiveOmniture', 'window', 'interactiveOmniture', 'window', 'interactiveOmniture', 'e68a3044', 'a988', '45a6', 'b59f', 'c346e82d664c', 'id', 'e68a3044', 'a988', '45a6', 'b59f', 'c346e82d664c', 'type', 'interactive', 'subtype', 'poll', 'embed', 'embed', 'true', 'userId', 'c3a12994', '0d15', '4748', '869d', '9dca491526fa', 'userType', 'ANONYMOUS', 'gameId', 'e68a3044', 'a988', '45a6', 'b59f', 'c346e82d664c', 'correctAnswers', '0', 'wrongAnswers', '0', 'answeredQuestions', '0', 'game', 'gameId', 'e68a3044', 'a988', '45a6', 'b59f', 'c346e82d664c', 'sectionId', 'politics', 'blogName', 'fact', 'checker', 'title', 'fact', 'checker', 'rating', 'murphy', '1', 'byline', 'glenn', 'kessler', 'bylineBioPage', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'www', 'washingtonpost', 'com', 'people', 'glenn', 'kessler', 'articleReferences', 'createdTimestamp', '1466118080690', 'archive', 'false', 'allowMoreThanOnce', 'false', 'createdBy', 'KESSLERGA', 'lastUpdatedBy', 'KESSLERGA', 'live', 'true', 'photoUploaded', 'false', 'shareUrl', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'wapo', 'st', '21pk0d8', 'commercialNode', 'politics', 'embedToggles', 'headline', 'false', 'byline', 'false', 'captchaProtected', 'false', 'question', 'questionId', '69a73c61', '9b60', '4a7d', '88b8', '73090f0e953c', 'questionText', 'p', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', 'p', 'excludeFromTrivia', 'false', 'articleReference', 'option', 'optionId', '9316b3ff', 'f09c', '4846', 'ad19', 'd61d85ee4ace', 'optionText', 'hasComment', 'false', 'optionId', 'd6f6a56a', 'e3cb', '47c5', '8e22', 'cf0e6b5acde8', 'optionText', 'hasComment', 'false', 'optionId', '6b850572', '808b', '4b93', 'aedf', '98ffd0a039e7', 'optionText', 'hasComment', 'false', 'optionId', '1a53846e', '4b40', '4340', 'b586', '701aefcd9b94', 'optionText', 'hasComment', 'false', 'optionId', '2de7a71d', '0242', '4b76', '9662', '87fe2a78bdee', 'optionText', 'hasComment', 'false', 'createdDate', '1466118080693', 'lastUpdated', '1466118122699', 'multipleSelectionAmount', '0', 'type', 'RATING', 'rating', 'iconType', 'PINOCCHIO', 'customIconName', 'PINOCCHIO', 'exclusive', 'false', 'allowDuplicate', 'false', 'lastUpdatedTimestamp', '1466118122697', '0', 'var', 'poll', 'JSON', 'parse', 'document', 'getElementById', 'pollData_e68a3044', 'a988', '45a6', 'b59f', 'c346e82d664c', 'innerHTML', 'var', 'viewType', 'embed', 'User', 'Poll', 'Results', 'Voting', 'close', 'poll', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', '20', '20', '20', '20', '20', 'Pardon', 'interruption', 'need', 'verify', 'actual', 'person', 'View', 'Results', 'non', 'scientific', 'user', 'poll', 'Results', 'statistically', 'valid', 'cannot', 'assume', 'reflect', 'view', 'Washington', 'Post', 'user', 'group', 'general', 'population', 'Share', 'poll', 'Share', 'Facebook', 'Share', 'Twitter', 'AR', '15', 'style', 'weapon', 'legal', 'United', 'States', '2004', 'ban', '10', 'year', 'coincidental', 'massive', 'increase', 'mass', 'shooting', 'country', '2004', 'Murphy', 'June', '15', 'another', 'problematic', 'claim', 'Murphy', 'staff', 'could', 'point', 'specific', 'data', 'back', 'significant', 'contrary', 'data', 'show', '10', 'year', 'assault', 'weapon', 'ban', 'little', 'effect', '2004', 'study', 'Justice', 'Department', 'found', 'ban', 'impact', 'gun', 'violence', 'mixed', 'best', 'ban', 'renew', 'likely', 'effect', 'gun', 'violence', 'likely', 'small', 'best', 'perhaps', 'small', 'reliable', 'measurement', 'report', 'say', 'assault', 'weapon', 'rarely', 'use', 'gun', 'crime', 'James', 'Alan', 'Fox', 'Northeastern', 'University', 'professor', 'collect', 'data', 'back', '1982', 'show', 'assault', 'weapon', 'account', '24', '6', 'percent', 'public', 'mass', 'shooting', 'Assault', 'weapon', 'commonplace', 'mass', 'shooting', 'gun', 'control', 'advocate', 'believe', 'Fox', 'write', '2012', 'article', 'journal', 'Homicide', 'Studies', 'Instead', 'semiautomatic', 'handgun', '47', '9', 'percent', 'far', 'prevalent', 'random', 'massacre', 'firearm', 'would', 'typically', 'classify', 'assault', 'weapon', 'assault', 'weapon', 'ban', 'make', 'difference', 'mass', 'shooting', 'significantly', 'accord', 'Fox', 'data', '1976', '1994', '18', 'mass', 'shooting', 'per', 'year', 'ban', '1995', '2004', '19', 'incident', 'per', 'year', 'ban', '2011', 'average', 'go', 'nearly', '21', '2016', 'study', 'publish', 'Applied', 'Economics', 'Benjamin', 'Blau', 'Utah', 'State', 'University', 'colleague', 'also', 'look', 'whether', 'state', 'federal', 'law', 'assault', 'rifle', 'affected', 'whether', 'weapon', 'use', 'public', 'shooting', '1982', '2014', 'study', 'seem', 'indicate', 'Federal', 'assault', 'rifle', 'ban', 'individual', 'State', 'assault', 'rifle', 'ban', 'affect', 'likelihood', 'assault', 'rifle', 'use', 'mass', 'shoot', 'Blau', 'say', 'Said', 'differently', 'type', 'ban', 'appear', 'deter', 'use', 'assault', 'rifle', 'mass', 'shoot', 'data', 'use', 'determine', 'whether', 'assault', 'rifle', 'ban', 'negatively', 'influence', 'likelihood', 'occurrence', 'mass', 'shoot', 'conclusive', 'colleague', 'Christopher', 'Ingraham', 'point', 'assault', 'style', 'rifle', 'use', 'seven', 'eight', 'high', 'profile', 'public', 'mass', 'shooting', 'since', 'July', 'last', 'year', 'certainly', 'raise', 'profile', 'weapon', 'data', 'far', 'show', 'link', 'use', 'weapon', 'lift', 'ban', 'Murphy', 'asserts', 'bottom', 'line', 'statistic', 'cite', 'story', 'told', 'Wednesday', 'show', 'undeniable', 'gun', 'kill', 'thousand', 'Americans', 'every', 'year', 'say', 'Murphy', 'spokesman', 'Chris', 'Harris', 'step', 'back', 'look', 'totality', 'data', 'easy', 'access', 'firearm', 'way', 'regulation', 'lead', 'increase', 'gun', 'death', 'homicide', 'suicide', 'true', 'U', 'compare', 'state', 'state', 'compare', 'U', 'nation', 'Pinocchio', 'Test', 'Murphy', 'say', 'coincidental', 'mass', 'shooting', 'increase', 'since', 'ban', 'lift', 'data', 'show', 'ban', 'particularly', 'effective', 'first', 'place', 'mass', 'shooting', 'increase', 'significantly', 'since', 'data', 'set', 'relatively', 'small', 'maybe', 'something', 'change', 'past', 'year', 'claim', 'worthy', 'Three', 'Pinocchios', 'Three', 'Pinocchios', 'rating', 'scale', 'var', 'urlRegex', 'b', 'http', 'Z0', '9', '_', 'Z0', '9', '_', 'ig', 'endPointString', 'Map', 'pattern', 'x3e', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'poll', 'washingtonpost', 'com', 'userpolls', 'game', 'webapi', 'poll', 'id', 'id', 'x3e', 'poll', 'content', 'x3e', 'Simple', 'Id', 'Content', 'Config', 'WPGames', 'WPGames', 'WPGames', 'common', 'WPGames', 'common', 'WPGames', 'common', 'api', 'WPGames', 'common', 'api', 'WPGames', 'common', 'api', '2558761d', '9989', '416f', 'a8c6', '9fdd7289fb97', 'endPointString', 'match', 'urlRegex', '0', 'replace', 'poll', 'var', 'shareURL', 'encodeURIComponent', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'wapo', 'st', '21piYOd', 'window', 'interactiveOmniture', 'window', 'interactiveOmniture', 'window', 'interactiveOmniture', '2558761d', '9989', '416f', 'a8c6', '9fdd7289fb97', 'id', '2558761d', '9989', '416f', 'a8c6', '9fdd7289fb97', 'type', 'interactive', 'subtype', 'poll', 'embed', 'embed', 'true', 'userId', 'a0847542', 'f10f', '4409', 'a330', '85f46a3b3c8b', 'userType', 'ANONYMOUS', 'gameId', '2558761d', '9989', '416f', 'a8c6', '9fdd7289fb97', 'correctAnswers', '0', 'wrongAnswers', '0', 'answeredQuestions', '0', 'game', 'gameId', '2558761d', '9989', '416f', 'a8c6', '9fdd7289fb97', 'sectionId', 'politics', 'blogName', 'fact', 'checker', 'title', 'fact', 'checker', 'rating', 'trump', '2', 'byline', 'glenn', 'kessler', 'bylineBioPage', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'www', 'washingtonpost', 'com', 'people', 'glenn', 'kessler', 'articleReferences', 'createdTimestamp', '1466118160561', 'archive', 'false', 'allowMoreThanOnce', 'false', 'createdBy', 'KESSLERGA', 'lastUpdatedBy', 'KESSLERGA', 'live', 'true', 'photoUploaded', 'false', 'shareUrl', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'wapo', 'st', '21piYOd', 'commercialNode', 'politics', 'embedToggles', 'headline', 'false', 'byline', 'false', 'captchaProtected', 'false', 'question', 'questionId', '43f3b445', 'ee45', '45b7', 'bfba', 'cf6132ccda74', 'questionText', 'p', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', 'p', 'excludeFromTrivia', 'false', 'articleReference', 'option', 'optionId', '9316b3ff', 'f09c', '4846', 'ad19', 'd61d85ee4ace', 'optionText', 'hasComment', 'false', 'optionId', 'd6f6a56a', 'e3cb', '47c5', '8e22', 'cf0e6b5acde8', 'optionText', 'hasComment', 'false', 'optionId', '6b850572', '808b', '4b93', 'aedf', '98ffd0a039e7', 'optionText', 'hasComment', 'false', 'optionId', '1a53846e', '4b40', '4340', 'b586', '701aefcd9b94', 'optionText', 'hasComment', 'false', 'optionId', '2de7a71d', '0242', '4b76', '9662', '87fe2a78bdee', 'optionText', 'hasComment', 'false', 'createdDate', '1466118160563', 'lastUpdated', '1466126246609', 'multipleSelectionAmount', '0', 'type', 'RATING', 'rating', 'iconType', 'PINOCCHIO', 'customIconName', 'PINOCCHIO', 'exclusive', 'false', 'allowDuplicate', 'false', 'lastUpdatedTimestamp', '1466126246607', '0', 'var', 'poll', 'JSON', 'parse', 'document', 'getElementById', 'pollData_2558761d', '9989', '416f', 'a8c6', '9fdd7289fb97', 'innerHTML', 'var', 'viewType', 'embed', 'User', 'Poll', 'Results', 'Voting', 'close', 'poll', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', '20', '20', '20', '20', '20', 'Pardon', 'interruption', 'need', 'verify', 'actual', 'person', 'View', 'Results', 'non', 'scientific', 'user', 'poll', 'Results', 'statistically', 'valid', 'cannot', 'assume', 'reflect', 'view', 'Washington', 'Post', 'user', 'group', 'general', 'population', 'Share', 'poll', 'Share', 'Facebook', 'Share', 'Twitter', 'America', 'absolutely', 'awash', 'easily', 'obtainable', 'firearm', 'go', 'gun', 'show', 'local', 'convention', 'center', 'come', 'away', 'fully', 'automatic', 'assault', 'rifle', 'without', 'background', 'check', 'likely', 'without', 'show', 'identification', 'card', 'wait', 'Sen', 'Minority', 'Leader', 'Harry', 'Reid', 'Nev', 'quote', 'al', 'Qaeda', 'spokesman', 'statement', 'Senate', 'floor', 'June', '15', '2016', 'indeed', 'al', 'Qaeda', 'spokesman', 'Adam', 'Gadahn', 'use', 'exact', 'language', '2011', 'American', 'born', 'Gadahn', 'later', 'kill', 'drone', 'strike', '2015', 'clip', 'even', 'terrorist', 'get', 'fact', 'wrong', 'Senate', 'leader', 'uncritically', 'quote', 'Reid', 'put', 'terrorist', 'talk', 'gun', 'show', 'loophole', 'specifically', 'point', 'flaw', 'nation', 'gun', 'law', 'allows', 'convict', 'terrorist', 'slip', 'big', 'wide', 'hole', 'slip', 'Actually', 'buy', 'fully', 'automatic', 'assault', 'rifle', 'gun', 'show', 'al', 'Qaeda', 'spokesman', 'extension', 'Reid', 'mix', 'semiautomatic', 'weapon', 'automatic', 'weapon', 'Semiautomatic', 'define', '1968', 'Gun', 'Control', 'Act', 'mean', 'one', 'pull', 'trigger', 'equates', 'one', 'bullet', 'leave', 'barrel', 'Fully', 'automatic', 'rifle', 'available', 'United', 'States', 'require', 'six', 'month', 'paperwork', 'Bureau', 'Alcohol', 'Tobacco', 'Firearms', 'Explosives', 'also', 'significantly', 'expensive', 'single', 'fire', 'counterpart', 'ban', 'many', 'state', 'Moreover', '1986', 'law', 'ban', 'new', 'one', 'automatic', 'weapon', 'purchase', 'would', 'old', 'one', 'Still', 'one', 'could', 'purchase', 'semiautomatic', 'weapon', 'retrofit', 'something', 'call', 'auto', 'sear', 'mimic', 'automatic', 'weapon', 'though', 'weapon', 'still', 'fit', 'definition', 'semiautomatic', 'modification', 'require', 'permission', 'ATF', 'video', 'describe', 'one', 'product', 'call', 'gun', 'show', 'loophole', 'refers', 'private', 'sale', 'within', 'state', 'line', 'license', 'gun', 'dealer', 'gun', 'show', 'must', 'run', 'background', 'check', 'Anyone', 'gun', 'show', 'sell', 'someone', 'state', 'must', 'run', 'background', 'check', 'number', 'state', 'include', 'California', 'New', 'York', 'require', 'background', 'check', 'gun', 'transaction', 'state', 'require', 'handgun', 'purchase', 'gun', 'show', 'require', 'background', 'check', 'matter', 'policy', 'matter', 'state', 'law', 'say', 'Gadahn', 'extensive', 'Reid', 'speak', 'sloppily', 'Reid', 'spokesman', 'decline', 'provide', 'record', 'comment', 'Pinocchio', 'Test', 'may', 'make', 'sense', 'award', 'Pinocchios', 'dead', 'al', 'Qaeda', 'operative', 'case', 'Reid', 'clearly', 'state', 'Gadahn', 'correct', 'even', 'believe', 'quote', 'make', 'noteworthy', 'point', 'Reid', 'quote', 'fully', 'automatic', 'line', 'twice', 'without', 'inform', 'listener', 'actually', 'possible', 'Moreover', 'Reid', 'make', 'comment', 'prepared', 'statement', 'publicly', 'release', 'news', 'release', 'could', 'still', 'update', 'correction', 'Two', 'Pinocchios', 'rating', 'scale', 'Send', 'u', 'fact', 'check', 'fill', 'form', 'Check', '2016', 'candidate', 'fact', 'check', 'page', 'Sign', 'Fact', 'Checker', 'weekly', 'newsletter', 'var', 'urlRegex', 'b', 'http', 'Z0', '9', '_', 'Z0', '9', '_', 'ig', 'endPointString', 'Map', 'pattern', 'x3e', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'poll', 'washingtonpost', 'com', 'userpolls', 'game', 'webapi', 'poll', 'id', 'id', 'x3e', 'poll', 'content', 'x3e', 'Simple', 'Id', 'Content', 'Config', 'WPGames', 'WPGames', 'WPGames', 'common', 'WPGames', 'common', 'WPGames', 'common', 'api', 'WPGames', 'common', 'api', 'WPGames', 'common', 'api', 'b80ce38c', 'fbcf', '4bfc', '985e', 'fc63b800449f', 'endPointString', 'match', 'urlRegex', '0', 'replace', 'poll', 'var', 'shareURL', 'encodeURIComponent', 'window', 'interactiveOmniture', 'window', 'interactiveOmniture', 'window', 'interactiveOmniture', 'b80ce38c', 'fbcf', '4bfc', '985e', 'fc63b800449f', 'id', 'b80ce38c', 'fbcf', '4bfc', '985e', 'fc63b800449f', 'type', 'interactive', 'subtype', 'poll', 'embed', 'embed', 'true', 'userId', 'd6b018de', '31f6', '46f9', '8dd6', 'fd20a63ac97a', 'userType', 'ANONYMOUS', 'gameId', 'b80ce38c', 'fbcf', '4bfc', '985e', 'fc63b800449f', 'correctAnswers', '0', 'wrongAnswers', '0', 'answeredQuestions', '0', 'game', 'gameId', 'b80ce38c', 'fbcf', '4bfc', '985e', 'fc63b800449f', 'sectionId', 'politics', 'blogName', 'fact', 'checker', 'title', 'fact', 'checker', 'rating', 'reid', 'byline', 'glenn', 'kessler', 'bylineBioPage', 'http', 'web', 'archive', 'org', 'web', '20160617095400', 'http', 'www', 'washingtonpost', 'com', 'people', 'glenn', 'kessler', 'articleReferences', 'createdTimestamp', '1466117973960', 'archive', 'false', 'allowMoreThanOnce', 'false', 'createdBy', 'KESSLERGA', 'lastUpdatedBy', 'KESSLERGA', 'live', 'false', 'photoUploaded', 'false', 'commercialNode', 'politics', 'embedToggles', 'headline', 'false', 'byline', 'false', 'captchaProtected', 'false', 'question', 'questionId', '1a6d57ae', 'd8a8', '43e7', '8b1e', 'f60ce8ccafa1', 'questionText', 'p', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', 'p', 'excludeFromTrivia', 'false', 'articleReference', 'option', 'optionId', '9316b3ff', 'f09c', '4846', 'ad19', 'd61d85ee4ace', 'optionText', 'hasComment', 'false', 'optionId', 'd6f6a56a', 'e3cb', '47c5', '8e22', 'cf0e6b5acde8', 'optionText', 'hasComment', 'false', 'optionId', '6b850572', '808b', '4b93', 'aedf', '98ffd0a039e7', 'optionText', 'hasComment', 'false', 'optionId', '1a53846e', '4b40', '4340', 'b586', '701aefcd9b94', 'optionText', 'hasComment', 'false', 'optionId', '2de7a71d', '0242', '4b76', '9662', '87fe2a78bdee', 'optionText', 'hasComment', 'false', 'createdDate', '1466117973962', 'lastUpdated', '1466117973962', 'multipleSelectionAmount', '0', 'type', 'RATING', 'rating', 'iconType', 'PINOCCHIO', 'customIconName', 'PINOCCHIO', 'exclusive', 'false', 'allowDuplicate', 'false', 'lastUpdatedTimestamp', '1466117973960', '0', 'var', 'poll', 'JSON', 'parse', 'document', 'getElementById', 'pollData_b80ce38c', 'fbcf', '4bfc', '985e', 'fc63b800449f', 'innerHTML', 'var', 'viewType', 'embed', 'User', 'Poll', 'Results', 'Voting', 'close', 'poll', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', '20', '20', '20', '20', '20', 'Pardon', 'interruption', 'need', 'verify', 'actual', 'person', 'View', 'Results', 'non', 'scientific', 'user', 'poll', 'Results', 'statistically', 'valid', 'cannot', 'assume', 'reflect', 'view', 'Washington', 'Post', 'user', 'group', 'general', 'population', 'Share', 'poll', 'Share', 'Facebook', 'Share', 'Twitter']\n"
     ]
    }
   ],
   "source": [
    "# Before cleaning \n",
    "\n",
    "print(len(lemma_stop(data[get_index[212853]][4])))\n",
    "print(lemma_stop(data[get_index[212853]][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116\n",
      "['know', 'States', 'impose', 'reasonable', 'limitation', 'less', 'gun', 'crime', 'less', 'homicide', 'Sen', 'Chris', 'Murphy', 'Conn', 'speak', 'Senate', 'floor', 'June', '15', 'Readers', 'ask', 'fact', 'check', 'gun', 'rhetoric', 'use', 'Democrats', 'wake', 'mass', 'shoot', 'Orlando', 'one', 'case', 'already', 'delve', 'material', 'claim', 'new', 'let', 'take', 'look', 'start', 'Murphy', 'statement', 'Facts', 'Murphy', 'staff', 'say', 'refer', 'chart', 'appear', 'National', 'Journal', '2015', 'turn', 'carefully', 'checked', 'chart', 'President', 'Obama', 'make', 'similar', 'carefully', 'phrase', 'claim', 'gun', 'death', 'Note', 'Murphy', 'refer', 'homicide', 'gun', 'crime', 'President', 'Obama', 'earn', 'Two', 'Pinocchios', 'Readers', 'check', 'full', 'fact', 'check', 'summary', 'note', 'gun', 'death', '60', 'percent', '2013', 'actually', 'suicide', 'data', 'use', 'National', 'Journal', 'chart', 'calculates', 'number', 'gun', 'related', 'death', 'per', '100', '000', 'people', 'include', 'gun', 'death', 'include', 'homicide', 'suicide', 'accidental', 'gun', 'death', 'legal', 'intervention', 'involve', 'firearm', 'remove', 'suicide', 'total', 'reran', 'number', 'case', 'make', 'huge', 'difference', 'Half', '10', 'state', 'low', 'gun', 'death', 'rate', 'turn', 'state', 'less', 'restrictive', 'gun', 'law', 'Moreover', 'counting', 'gun', 'law', 'certainly', 'open', 'interpretation', 'also', 'affect', 'outcome', 'enough', 'count', 'law', 'figure', 'reason', 'gun', 'death', 'low', 'one', 'state', 'another', 'One', 'would', 'need', 'specifically', 'determine', 'whether', 'certain', 'law', 'effect', 'time', 'gun', 'death', 'rate', 'state', 'instance', 'Murphy', 'claim', 'worthy', 'Three', 'Pinocchios', 'specifically', 'refer', 'homicide', 'rather', 'gun', 'death', 'Three', 'Pinocchios', 'rating', 'scale', 'var', 'x3e', 'id', 'x3e', 'poll', 'content', 'x3e', 'Simple', 'Id', 'Content', 'checker', 'rating', 'murphy', '1', 'byline', 'glenn', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', '0', 'var', 'var', 'viewType', 'embed', 'User', 'Poll', 'Results', 'Voting', 'close', 'poll', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', '20', '20', '20', '20', '20', 'Pardon', 'interruption', 'need', 'verify', 'actual', 'person', 'View', 'Results', 'non', 'scientific', 'user', 'poll', 'Results', 'statistically', 'valid', 'cannot', 'assume', 'reflect', 'view', 'Washington', 'Post', 'user', 'group', 'general', 'population', 'Share', 'poll', 'Share', 'Facebook', 'Share', 'Twitter', 'AR', '15', 'style', 'weapon', 'legal', 'United', 'States', '2004', 'ban', '10', 'year', 'coincidental', 'massive', 'increase', 'mass', 'shooting', 'country', '2004', 'Murphy', 'June', '15', 'another', 'problematic', 'claim', 'Murphy', 'staff', 'could', 'point', 'specific', 'data', 'back', 'significant', 'contrary', 'data', 'show', '10', 'year', 'assault', 'weapon', 'ban', 'little', 'effect', '2004', 'study', 'Justice', 'Department', 'found', 'ban', 'impact', 'gun', 'violence', 'mixed', 'best', 'ban', 'renew', 'likely', 'effect', 'gun', 'violence', 'likely', 'small', 'best', 'perhaps', 'small', 'reliable', 'measurement', 'report', 'say', 'assault', 'weapon', 'rarely', 'use', 'gun', 'crime', 'James', 'Alan', 'Fox', 'Northeastern', 'University', 'professor', 'collect', 'data', 'back', '1982', 'show', 'assault', 'weapon', 'account', '24', '6', 'percent', 'public', 'mass', 'shooting', 'Assault', 'weapon', 'commonplace', 'mass', 'shooting', 'gun', 'control', 'advocate', 'believe', 'Fox', 'write', '2012', 'article', 'journal', 'Homicide', 'Studies', 'Instead', 'semiautomatic', 'handgun', '47', '9', 'percent', 'far', 'prevalent', 'random', 'massacre', 'firearm', 'would', 'typically', 'classify', 'assault', 'weapon', 'assault', 'weapon', 'ban', 'make', 'difference', 'mass', 'shooting', 'significantly', 'accord', 'Fox', 'data', '1976', '1994', '18', 'mass', 'shooting', 'per', 'year', 'ban', '1995', '2004', '19', 'incident', 'per', 'year', 'ban', '2011', 'average', 'go', 'nearly', '21', '2016', 'study', 'publish', 'Applied', 'Economics', 'Benjamin', 'Blau', 'Utah', 'State', 'University', 'colleague', 'also', 'look', 'whether', 'state', 'federal', 'law', 'assault', 'rifle', 'affected', 'whether', 'weapon', 'use', 'public', 'shooting', '1982', '2014', 'study', 'seem', 'indicate', 'Federal', 'assault', 'rifle', 'ban', 'individual', 'State', 'assault', 'rifle', 'ban', 'affect', 'likelihood', 'assault', 'rifle', 'use', 'mass', 'shoot', 'Blau', 'say', 'Said', 'differently', 'type', 'ban', 'appear', 'deter', 'use', 'assault', 'rifle', 'mass', 'shoot', 'data', 'use', 'determine', 'whether', 'assault', 'rifle', 'ban', 'negatively', 'influence', 'likelihood', 'occurrence', 'mass', 'shoot', 'conclusive', 'colleague', 'Christopher', 'Ingraham', 'point', 'assault', 'style', 'rifle', 'use', 'seven', 'eight', 'high', 'profile', 'public', 'mass', 'shooting', 'since', 'July', 'last', 'year', 'certainly', 'raise', 'profile', 'weapon', 'data', 'far', 'show', 'link', 'use', 'weapon', 'lift', 'ban', 'Murphy', 'asserts', 'bottom', 'line', 'statistic', 'cite', 'story', 'told', 'Wednesday', 'show', 'undeniable', 'gun', 'kill', 'thousand', 'Americans', 'every', 'year', 'say', 'Murphy', 'spokesman', 'Chris', 'Harris', 'step', 'back', 'look', 'totality', 'data', 'easy', 'access', 'firearm', 'way', 'regulation', 'lead', 'increase', 'gun', 'death', 'homicide', 'suicide', 'true', 'U', 'compare', 'state', 'state', 'compare', 'U', 'nation', 'Pinocchio', 'Test', 'Murphy', 'say', 'coincidental', 'mass', 'shooting', 'increase', 'since', 'ban', 'lift', 'data', 'show', 'ban', 'particularly', 'effective', 'first', 'place', 'mass', 'shooting', 'increase', 'significantly', 'since', 'data', 'set', 'relatively', 'small', 'maybe', 'something', 'change', 'past', 'year', 'claim', 'worthy', 'Three', 'Pinocchios', 'Three', 'Pinocchios', 'rating', 'scale', 'var', 'x3e', 'id', 'x3e', 'poll', 'content', 'x3e', 'Simple', 'Id', 'Content', 'checker', 'rating', 'trump', '2', 'byline', 'glenn', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', '0', 'var', 'var', 'viewType', 'embed', 'User', 'Poll', 'Results', 'Voting', 'close', 'poll', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', '20', '20', '20', '20', '20', 'Pardon', 'interruption', 'need', 'verify', 'actual', 'person', 'View', 'Results', 'non', 'scientific', 'user', 'poll', 'Results', 'statistically', 'valid', 'cannot', 'assume', 'reflect', 'view', 'Washington', 'Post', 'user', 'group', 'general', 'population', 'Share', 'poll', 'Share', 'Facebook', 'Share', 'Twitter', 'America', 'absolutely', 'awash', 'easily', 'obtainable', 'firearm', 'go', 'gun', 'show', 'local', 'convention', 'center', 'come', 'away', 'fully', 'automatic', 'assault', 'rifle', 'without', 'background', 'check', 'likely', 'without', 'show', 'identification', 'card', 'wait', 'Sen', 'Minority', 'Leader', 'Harry', 'Reid', 'Nev', 'quote', 'al', 'Qaeda', 'spokesman', 'statement', 'Senate', 'floor', 'June', '15', '2016', 'indeed', 'al', 'Qaeda', 'spokesman', 'Adam', 'Gadahn', 'use', 'exact', 'language', '2011', 'American', 'born', 'Gadahn', 'later', 'kill', 'drone', 'strike', '2015', 'clip', 'even', 'terrorist', 'get', 'fact', 'wrong', 'Senate', 'leader', 'uncritically', 'quote', 'Reid', 'put', 'terrorist', 'talk', 'gun', 'show', 'loophole', 'specifically', 'point', 'flaw', 'nation', 'gun', 'law', 'allows', 'convict', 'terrorist', 'slip', 'big', 'wide', 'hole', 'slip', 'Actually', 'buy', 'fully', 'automatic', 'assault', 'rifle', 'gun', 'show', 'al', 'Qaeda', 'spokesman', 'extension', 'Reid', 'mix', 'semiautomatic', 'weapon', 'automatic', 'weapon', 'Semiautomatic', 'define', '1968', 'Gun', 'Control', 'Act', 'mean', 'one', 'pull', 'trigger', 'equates', 'one', 'bullet', 'leave', 'barrel', 'Fully', 'automatic', 'rifle', 'available', 'United', 'States', 'require', 'six', 'month', 'paperwork', 'Bureau', 'Alcohol', 'Tobacco', 'Firearms', 'Explosives', 'also', 'significantly', 'expensive', 'single', 'fire', 'counterpart', 'ban', 'many', 'state', 'Moreover', '1986', 'law', 'ban', 'new', 'one', 'automatic', 'weapon', 'purchase', 'would', 'old', 'one', 'Still', 'one', 'could', 'purchase', 'semiautomatic', 'weapon', 'retrofit', 'something', 'call', 'auto', 'sear', 'mimic', 'automatic', 'weapon', 'though', 'weapon', 'still', 'fit', 'definition', 'semiautomatic', 'modification', 'require', 'permission', 'ATF', 'video', 'describe', 'one', 'product', 'call', 'gun', 'show', 'loophole', 'refers', 'private', 'sale', 'within', 'state', 'line', 'license', 'gun', 'dealer', 'gun', 'show', 'must', 'run', 'background', 'check', 'Anyone', 'gun', 'show', 'sell', 'someone', 'state', 'must', 'run', 'background', 'check', 'number', 'state', 'include', 'California', 'New', 'York', 'require', 'background', 'check', 'gun', 'transaction', 'state', 'require', 'handgun', 'purchase', 'gun', 'show', 'require', 'background', 'check', 'matter', 'policy', 'matter', 'state', 'law', 'say', 'Gadahn', 'extensive', 'Reid', 'speak', 'sloppily', 'Reid', 'spokesman', 'decline', 'provide', 'record', 'comment', 'Pinocchio', 'Test', 'may', 'make', 'sense', 'award', 'Pinocchios', 'dead', 'al', 'Qaeda', 'operative', 'case', 'Reid', 'clearly', 'state', 'Gadahn', 'correct', 'even', 'believe', 'quote', 'make', 'noteworthy', 'point', 'Reid', 'quote', 'fully', 'automatic', 'line', 'twice', 'without', 'inform', 'listener', 'actually', 'possible', 'Moreover', 'Reid', 'make', 'comment', 'prepared', 'statement', 'publicly', 'release', 'news', 'release', 'could', 'still', 'update', 'correction', 'Two', 'Pinocchios', 'rating', 'scale', 'Send', 'u', 'fact', 'check', 'fill', 'form', 'Check', '2016', 'candidate', 'fact', 'check', 'page', 'Sign', 'Fact', 'Checker', 'weekly', 'newsletter', 'var', 'x3e', 'id', 'x3e', 'poll', 'content', 'x3e', 'Simple', 'Id', 'Content', 'shareURL', 'encodeURIComponent', 'checker', 'rating', 'reid', 'byline', 'glenn', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', '0', 'var', 'var', 'viewType', 'embed', 'User', 'Poll', 'Results', 'Voting', 'close', 'poll', 'would', 'rate', 'claim', 'check', 'mark', 'mean', 'think', 'statement', 'true', 'agree', 'rating', '20', '20', '20', '20', '20', 'Pardon', 'interruption', 'need', 'verify', 'actual', 'person', 'View', 'Results', 'non', 'scientific', 'user', 'poll', 'Results', 'statistically', 'valid', 'cannot', 'assume', 'reflect', 'view', 'Washington', 'Post', 'user', 'group', 'general', 'population', 'Share', 'poll', 'Share', 'Facebook', 'Share', 'Twitter']\n"
     ]
    }
   ],
   "source": [
    "# After cleaning (removing JSON, HTML, etc)\n",
    "\n",
    "cleaned_doc=clean_document(data[get_index[212853]][4])\n",
    "print(len(lemma_stop(cleaned_doc)))\n",
    "print(lemma_stop(cleaned_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsbw8tNbrJfL"
   },
   "source": [
    "*Run the following cell once after all pre-processing (removing JSON etc), and store final lemmatized contents of all docs:* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibq9gAauMI5Q"
   },
   "outputs": [],
   "source": [
    "# Run once after all pre-processing \n",
    "\n",
    "\n",
    "# # Tester code\n",
    "# import time\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# for i in range(0, len(data)) :\n",
    "#     f_content = clean_document(data[i][4])\n",
    "#     contents = f_content\n",
    "#     # print(contents)\n",
    "#     final = lemma_stop (contents)\n",
    "# #     print(type(final))\n",
    "#     # print (final)\n",
    "    \n",
    "# print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a temporary smaller dataset\n",
    "\n",
    "subset = []\n",
    "counter = 0\n",
    "for document in data:\n",
    "    subset.append(document)\n",
    "    counter += 1\n",
    "    if counter == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:44<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.94978761672974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "titles = []\n",
    "contents = []\n",
    "for document in tqdm(subset):\n",
    "    modifiedContent = replace_dates(document[4])\n",
    "    modifiedContent = lemma_stop(modifiedContent)\n",
    "    modifiedTitle = lemma_stop((document[1]))\n",
    "    # modifiedContent = lemma_stop(clean_document(document[4]))\n",
    "    # modifiedTitle = lemma_stop(clean_document(document[1]))\n",
    "    titles.append(modifiedTitle)\n",
    "    contents.append(modifiedContent)\n",
    "    \n",
    "print(time.time() - start)  # 110.26236414909363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "contents_temp = contents\n",
    "titles_temp = titles\n",
    "for i in range(1000):\n",
    "    for j in range(len(contents[i])):\n",
    "        contents[i][j] = unidecode.unidecode(contents[i][j])\n",
    "    for j in range(len(titles[i])):\n",
    "        titles[i][j] = unidecode.unidecode(titles[i][j])\n",
    "# for document in contents_temp:\n",
    "#     for word in document:\n",
    "#         word = unidecode.unidecode(word)\n",
    "# for title in titles_temp:\n",
    "#     for word in title:\n",
    "#         word = unidecode.unidecode(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr-HGZhDrJfT"
   },
   "outputs": [],
   "source": [
    "import trie\n",
    "\n",
    "# Create map from docID of the document to an object of class Node \n",
    "# (i.e, the corresponding document trie structure)\n",
    "# ex. if the docID of the document is 1, \n",
    "# getReference[1] gives the object which is the trie structure of docID 1\n",
    "\n",
    "getReference = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentRoot = []\n",
    "collection = trie.CollectionNode()\n",
    "\n",
    "# initializing the root for 1000 documents\n",
    "for i in range(1000):\n",
    "    newDocument = trie.Node()\n",
    "    documentRoot.append(newDocument)\n",
    "    getReference[get_docID[i]] = newDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:07<00:00, 128.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.191497802734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# creating the documents\n",
    "\n",
    "max_tf = {}\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "for i in tqdm(range(1000)):\n",
    "    for w in contents_temp[i]:\n",
    "        collection.add_(w, 0, get_docID[i])\n",
    "        documentRoot[i].add(w, 0)\n",
    "        if get_docID[i] in max_tf:\n",
    "            max_tf[get_docID[i]] = max(documentRoot[i].count_words(w, 0), max_tf[get_docID[i]])\n",
    "        else:\n",
    "            max_tf[get_docID[i]] = documentRoot[i].count_words(w, 0)\n",
    "\n",
    "print(time.time() - start)  #39.19705152511597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:41<00:00, 24.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import queue\n",
    "\n",
    "documentLength = {}\n",
    "N = len(documentRoot)\n",
    "\n",
    "for i in tqdm(range(len(documentRoot))):\n",
    "    \n",
    "    docID = get_docID[i]\n",
    "    length = 0\n",
    "    document = documentRoot[i]\n",
    "    q = queue.Queue()\n",
    "    q.put([document, ''])\n",
    "\n",
    "    while q.qsize() > 0:\n",
    "\n",
    "        current = q.get()\n",
    "        reference = current[0]\n",
    "        word = current[1]\n",
    "\n",
    "        if reference.words > 0:\n",
    "            df = len(collection.get_doc_list(word, 0))\n",
    "            idf = math.log10(N/df)\n",
    "            # print(word, reference.words, df)\n",
    "            length += (reference.words * idf) ** 2\n",
    "\n",
    "        for i in range(256):\n",
    "            if reference.children[i] is not None:\n",
    "                new_word = word + chr(i)\n",
    "                q.put([reference.children[i], new_word])\n",
    "\n",
    "    # print(length**0.5)\n",
    "    documentLength[docID] = length**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.getsizeof(documentRoot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go9w6bB9rJfg",
    "outputId": "2e5b7bc8-2e68-4de8-f81d-a142a989c902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Obama', 'go', 'walk']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "query = 'Obama went for a walk'\n",
    "final_query = replace_dates(query)\n",
    "final_query = lemma_stop(final_query)\n",
    "for i in range(len(final_query)):\n",
    "    final_query[i] = unidecode.unidecode(final_query[i])\n",
    "print(final_query)\n",
    "print(len(final_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4Kqgk9hrJfj",
    "outputId": "04bfaa8a-8053-4ab7-e55a-cee2d47edb6f"
   },
   "outputs": [],
   "source": [
    "tf_query = {}\n",
    "for w in final_query:\n",
    "    if w not in tf_query:\n",
    "        tf_query[w] = 1\n",
    "    else:\n",
    "        tf_query[w] += 1\n",
    "        \n",
    "    # Test code just to see distribution of query terms in the documents\n",
    "    \n",
    "    # print(w)\n",
    "    # df = len(collection.get_doc_list(w,0))\n",
    "    # print(collection.get_doc_list(w,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(documentRoot[1]), get_docID[1])\n",
    "# document = documentRoot[1]\n",
    "# N = len(documentRoot)\n",
    "\n",
    "# import queue\n",
    "# import math\n",
    "\n",
    "# length = 0\n",
    "# q = queue.Queue()\n",
    "# q.put([document, ''])\n",
    "\n",
    "# while q.qsize() > 0:\n",
    "    \n",
    "#     current = q.get()\n",
    "#     reference = current[0]\n",
    "#     word = current[1]\n",
    "    \n",
    "#     if reference.words > 0:\n",
    "#         df = len(collection.get_doc_list(word, 0))\n",
    "#         idf = math.log10(N/df)\n",
    "#         # print(word, reference.words, df)\n",
    "#         length += (reference.words * idf) ** 2\n",
    "    \n",
    "#     for i in range(256):\n",
    "#         if reference.children[i] is not None:\n",
    "#             new_word = word + chr(i)\n",
    "#             q.put([reference.children[i], new_word])\n",
    "\n",
    "# print(length**0.5)\n",
    "# print(replace_dates(subset[get_index[104]][4]))\n",
    "# replace_dates('12/12')\n",
    "# lemma_stop('12Dec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBHDg-lJrJfo"
   },
   "source": [
    "***Ranked Retrieval based on TF-IDF Score :***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfT-kdUqrJfp",
    "outputId": "3c95efd0-76c9-4dfe-e425-e79c089931ee",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Term in query =  Obama\n",
      "\n",
      "df =  37\n",
      "idf =  1.431798275933005\n",
      "-------------------------------------\n",
      "Term in query =  go\n",
      "\n",
      "df =  706\n",
      "idf =  0.15119529894819622\n",
      "-------------------------------------\n",
      "Term in query =  walk\n",
      "\n",
      "df =  135\n",
      "idf =  0.8696662315049939\n",
      "\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  51\n",
      "Keywords:\n",
      "Obama -108.81666897090838 76\n",
      "go -3.023905978963924 20\n",
      "\n",
      "\n",
      "... .embed-container iframe, .embed-container object, .embed-container embed { position: absolute top: 0 left: 0 width: 100% height: 100% }And then Michelle Obama joined the party. That October, Mrs. Obama held a Vine Q&ampampA for her Let’s Move! initiative, calling on kids and their families to send in video questions about healthy eating, cooking, and gardening. Over the course of five days, she answered a series of family-friendly queries ranging from \"What’s  ... \n",
      "tf-idf score= 12.955883803513126\n",
      "\n",
      "doc ID =  6846\n",
      "Keywords:\n",
      "Obama -37.22675517425813 26\n",
      "go -0.9071717936891773 6\n",
      "\n",
      "\n",
      "... morning, a group blocked off Chairman Tom Wheeler's driveway to decry the latest series of rules. And now, President Barack Obama has urged the FCC to take a stand and treat broadband more like a utility than a web portal.Obama's loose four-point proposal is a boon to most net neutrality supporters: he's asking for broadband to be classified as a Title II common carrier, putting it in the same category  ... \n",
      "tf-idf score= 7.069235865141152\n",
      "\n",
      "doc ID =  52\n",
      "Keywords:\n",
      "Obama -11.45438620746404 8\n",
      "go -9.071717936891773 60\n",
      "walk -3.4786649260199756 4\n",
      "\n",
      "\n",
      "... Comcast and Verizon for their throttling antics and intense Congressional lobbying. Midway through the segment, Oliver dryly pointed to President Obama’s appointment of former cable and wireless lobbyist Wheeler as the new head of the Federal Communications Commission — \"the equivalent of needing a babysitter and hiring a dingo.\" The DragonslayerA year ago, FCC Chairman Tom Wheeler saved the internet. In this exclusive interview, he tells us what’s nextBy Nilay  ... \n",
      "tf-idf score= 5.640368814501952\n",
      "\n",
      "doc ID =  6812\n",
      "Keywords:\n",
      "Obama -14.31798275933005 10\n",
      "\n",
      "\n",
      "This morning brought some alarming news. Just two days after President Obama promised a proportionate response to the North Korean attack on Sony, the country mysteriously disappeared from the internet and stayed offline for the next 10 hours. Given the timing, the question was inevitable: was this the retaliation Obama had promised? But while it's tempting to connect the two, early  ... \n",
      "tf-idf score= 3.390438239541342\n",
      "\n",
      "doc ID =  6998\n",
      "Keywords:\n",
      "Obama -14.31798275933005 10\n",
      "go -0.6047811957927849 4\n",
      "\n",
      "\n",
      "... Patriot Act, it was kept secret from the public and even parts of Congress.After the program was revealed, President Barack Obama, some members of Congress, and intelligence community leaders spoke out in defense of it. Then-NSA head Keith Alexander argued that \"fewer than 300\" unique numbers had been queried in 2012, saying that the program was vital in foiling terrorist plots. These plots would fail to materialize, and an oversight  ... \n",
      "tf-idf score= 3.357860411236363\n",
      "\n",
      "doc ID =  7141\n",
      "Keywords:\n",
      "Obama -11.45438620746404 8\n",
      "go -1.2095623915855698 8\n",
      "\n",
      "\n",
      "... we'll continue to encourage Congress to take additional steps to address all of the reforms we believe are needed.As one Obama aide told Politico more simply, the deal was \"understood to resolve the question of transparency around national security.\" As far as the courts were concerned, the tech companies had won.It's the kind of compromise President Obama lovesSo what did they win, exactly? On the transparency side, companies get to  ... \n",
      "tf-idf score= 3.047488014505279\n",
      "\n",
      "doc ID =  62\n",
      "Keywords:\n",
      "Obama -8.59078965559803 6\n",
      "go -4.233468370549494 28\n",
      "walk -1.7393324630099878 2\n",
      "\n",
      "\n",
      "... relations last December, the socialist archipelago has been undergoing an experiment: a slight but steady increase in internet access. The Obama administration, which had been busy trying to sneak private internet connections into Cuba before the détente, has made boosting information technology one of its top negotiation priorities. On September 21st, it lifted restrictions on US telecommunications companies doing business in Cuba, spawning dreams of a telecom gold rush.But there  ... \n",
      "tf-idf score= 2.630602146074495\n",
      "\n",
      "doc ID =  7066\n",
      "Keywords:\n",
      "Obama -11.45438620746404 8\n",
      "go -1.511952989481962 10\n",
      "\n",
      "\n",
      "... send troops into Russia, and have so far chosen to pressure the Kremlin through economic and diplomatic channels. President Barack Obama and his Russian counterpart, Vladimir Putin, have already exchanged targeted economic sanctions, and Russia was excluded from a meeting of the elite G8 group of countries last month. This week, NASA&ampnbspsuspended most of its operations with Russia's space agency, citing Russia's \"ongoing violation of Ukraine's sovereignty and territorial integrity.\"Western  ... \n",
      "tf-idf score= 2.4795177930824917\n",
      "\n",
      "doc ID =  7208\n",
      "Keywords:\n",
      "Obama -14.31798275933005 10\n",
      "go -1.8143435873783547 12\n",
      "\n",
      "\n",
      "... Healthcare.gov.It&amprsquos the first time a major law has depended so heavily on the internet. Since the ACA passed, President Barack Obama has reportedly ended every health care meeting the same way: &ampldquoIf the website doesn&amprsquot work, nothing else matters.&amprdquo \"The system is unavailable\"Despite his prescient warning, the president didn&amprsquot seem to realize that the website not working was an actual possibility.Healthcare.gov was frighteningly dysfunctional on day one. Users experienced multi-hour  ... \n",
      "tf-idf score= 2.2397403357767005\n",
      "\n",
      "doc ID =  7297\n",
      "Keywords:\n",
      "Obama -8.59078965559803 6\n",
      "\n",
      "\n",
      "... negotiations and will need to be addressed at some point this year, with Congressional Republicans as far apart from the Obama administration and Democratic leadership as ever. Hence, #MintTheCoin.We may never know the real limits of the law It was never entirely clear whether using a platinum coin to expand the debt limit would survive a challenge in federal court, although a co-author of the 1997 bill was quite sure  ... \n",
      "tf-idf score= 1.8725142806668218\n"
     ]
    }
   ],
   "source": [
    "# scores[i] stores the dot product of the tf-idf score vectors of the query and document of docID i in the corpus\n",
    "scores = {}\n",
    "\n",
    "# N is the total number of documents in the corpus\n",
    "N = len(documentRoot)\n",
    "\n",
    "# wordsInDoc[i] is a sorted list of (word, score) tuples where\n",
    "# score is the tf-idf score for the (word, <ith doc>) pair\n",
    "wordsInDoc = {}\n",
    "\n",
    "factor = {}\n",
    "\n",
    "import math\n",
    "import bisect\n",
    "\n",
    "for query_term in tf_query:\n",
    "    \n",
    "    docs_having_query_term = collection.get_doc_list(query_term, 0)\n",
    "    df = len(docs_having_query_term)\n",
    "    idf = 0\n",
    "    \n",
    "    print('-------------------------------------')\n",
    "    print('Term in query = ', query_term)\n",
    "    # print('List of documents with this term=', docs_having_query_term)\n",
    "    print()\n",
    "    \n",
    "    if df == 0:\n",
    "        idf = 0\n",
    "    else:\n",
    "        idf = math.log10(N/df)\n",
    "        \n",
    "    print('df = ',df)\n",
    "    print('idf = ',idf)\n",
    "    \n",
    "    tfidf_query = tf_query[query_term] * idf\n",
    "        \n",
    "    for docID in docs_having_query_term:\n",
    "        # print(docID)\n",
    "        tf_doc = getReference[docID].count_words(query_term, 0)\n",
    "        # print('tf for doc',docID,'is',tf_doc)\n",
    "        # tfidf_doc_query = tf_doc * idf\n",
    "        # tfidf_doc = 1 + math.log10(tf_doc)\n",
    "        tfidf_doc = (tf_doc)\n",
    "        # tfidf_doc_query = (tf_doc)\n",
    "        \n",
    "        # print('tfidf for doc',doc,'is',tfidf_doc)\n",
    "        # print()\n",
    "        \n",
    "        if docID not in scores:\n",
    "            scores[docID] = (tfidf_query * tfidf_doc)\n",
    "            wordsInDoc[docID] = []\n",
    "            bisect.insort(wordsInDoc[docID], [-tfidf_query * tfidf_doc, query_term])\n",
    "            factor[docID] = idf\n",
    "        else:\n",
    "            scores[docID] += (tfidf_query * tfidf_doc)\n",
    "            bisect.insort(wordsInDoc[docID], [-tfidf_query * tfidf_doc, query_term])\n",
    "            factor[docID] += idf\n",
    "        \n",
    "for docID in scores:\n",
    "    if documentLength[docID] != 0:\n",
    "        scores[docID] = scores[docID]/ math.sqrt(documentLength[docID])\n",
    "        scores[docID] *= factor[docID]\n",
    "\n",
    "\n",
    "sorted_scores = sorted(scores.items(), key = lambda kv : kv[1] , reverse = True)\n",
    "\n",
    "maxshow = min(10, len(scores))\n",
    "\n",
    "print('\\n\\n')\n",
    "print('============================================')\n",
    "\n",
    "for i in range(maxshow):\n",
    "    # print(i)\n",
    "    print()\n",
    "    docID = sorted_scores[i][0]\n",
    "    print('doc ID = ', docID)\n",
    "    cnt = 0\n",
    "    print('Keywords:')\n",
    "    for j in range(len(wordsInDoc[docID])):\n",
    "        print(wordsInDoc[docID][j][1], wordsInDoc[docID][j][0], end = ' ')\n",
    "        print(getReference[docID].count_words(wordsInDoc[docID][j][1], 0))\n",
    "    print()\n",
    "    print()\n",
    "    count = 0\n",
    "    found = 0\n",
    "    words_before=queue.Queue()\n",
    "    at_start = 1\n",
    "    display = \"\"\n",
    "    for word in subset[get_index[docID]][4].split():\n",
    "            \n",
    "        check_with=replace_dates(word)\n",
    "        if len(lemma_stop(check_with)) > 0:\n",
    "            check_with=lemma_stop(check_with)[0]\n",
    "        else:\n",
    "            check_with=word\n",
    "        \n",
    "        if check_with == wordsInDoc[docID][0][1]:\n",
    "            found=1\n",
    "            \n",
    "        if found == 1:\n",
    "            display = display + word + \" \"\n",
    "            count += 1\n",
    "            if count == 50:\n",
    "                break\n",
    "        if found == 0:\n",
    "            words_before.put(word)\n",
    "            if words_before.qsize()>20:\n",
    "                remove=words_before.get()\n",
    "                at_start=0\n",
    "                \n",
    "    if not at_start:\n",
    "        print('...', end = ' ')\n",
    "    while words_before.qsize() > 0:\n",
    "        print(words_before.get(), end = ' ')\n",
    "    print(display, end = ' ')\n",
    "    print('...', end = ' ')\n",
    "    print()\n",
    "    print('tf-idf score=', sorted_scores[i][1])\n",
    "    \n",
    "# print('\\n\\n')\n",
    "# print('============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11Sep']\n"
     ]
    }
   ],
   "source": [
    "check_with=replace_dates('9/11')\n",
    "check_with=str(lemma_stop(check_with))\n",
    "print(check_with)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqsqWNnFNOhO"
   },
   "source": [
    "***Original Text :***\n",
    "\n",
    "      We’re back in Dale Cooper’s position, wandering through a freshly revived world, and trying to catch up with the ways it’s moved on in his absence.\n",
    "\n",
    "***Processed Text :***\n",
    "\n",
    "      We back Dale Cooper position wander freshly revive world try catch way move absence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      This morning brought some alarming news. Just two days after President Obama promised a proportionate response to the North Korean attack on Sony, the country mysteriously disappeared from the internet and stayed offline for the next 10 hours. Given the timing, the question was inevitable: was this the retaliation Obama had promised? But while it's tempting to connect the two, early reports suggest it's very unlikely that the downtime was the work of a government actor. \"I'm quite sure that this is not the work of the US government.\"For a start, the timing doesn't add up. Arbor Networks' traffic monitoring project Atlas has been tracking denial of service attacks against North Korea all week, and it saw the first signs of an attack on Thursday, a full day before the FBI confirmed North Korean involvement. In his speech this Friday, President Obama pledged a proportionate response from the US, but also said he was still waiting for retaliatory options to be presented to him in the wake of the FBI's report, implying that he had not yet taken action. According to Atlas' data, the denial-of-service attacks against North Korea had already begun when Obama made that announcement, although they were not yet strong enough to bring the connection down entirely.  A graph from Atlas tracking the volume of attacks sent to North Korean IPs. (Note: The data from the 22nd is incomplete.)Denial-of-service attacks work by flooding a connection or server with so much phony traffic that it becomes impossible for legitimate traffic to get through. In North Korea's case, that connection is the country's single link to China Unicom, the pathway for all of the country's limited internet traffic. But while the flood of traffic eventually grew large enough to overwhelm the connection, Atlas' research suggests it was primarily directed at the public-facing websites for the DPRK and Kim Il-sung University, neither of which seem to be likely targets for a military operation. More importantly, the slow ramp-up of the attacks suggests group-limited capabilities. If Obama had really ordered a North Korean blackout, the resulting attack would have taken seconds, not days — and stayed offline for significantly more than 10 hours. \"I’m quite sure that this is not the work of the US government,\" concludes Atlas' Dan Holden. \"Much like a real world strike from the US, you probably wouldn’t know about it until it was too late. This is not the modus operandi of any government work.\"The content delivery network CloudFlare, which does significant work in denial-of-service mitigation, took a similar line. Reached by The Verge, CloudFlare CEO Matthew Prince broke out three alternate scenarios: a hardware failure, a voluntary internet shutdown, or a cut-off on the part of China Unicom. \"I do think that it's highly unlikely that, if this was caused by an attack, that it was necessarily sponsored by a nation state,\" Prince said. Given the exceptionally low barrier to entry for a denial-of-service attack, nearly anyone on the web could be behind North Korea's connectivity problems. In fact, a number of online groups are already claiming responsibility, including an Anonymous-affiliated group called Lizard Unit. As with any Anonymous-linked claim, it's best to be skeptical — but as Prince put it, \"I'd be far more surprised if it was a government launching the attack than I would if it was a kid in a Guy Fawkes mask.\"12/22 23:15pm ET: Updated to reflect North Korean connections coming back online.\n"
     ]
    }
   ],
   "source": [
    "print(subset[get_index[6812]][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
