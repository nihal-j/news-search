{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__1Nxb4gRIeN"
   },
   "source": [
    "Done so far :\n",
    "\n",
    "\n",
    "*   Lemmatization\n",
    "*   Stop Words Removal\n",
    "\n",
    "Verify :\n",
    "\n",
    "* Normalization - removing accents, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qZ-TMc9SVHl"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "####### After importing nltk, run the following only once ######\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LpQkEVQOSVHr"
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag=nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict={\"J\": wordnet.ADJ, \n",
    "              \"N\": wordnet.NOUN,\n",
    "              \"V\": wordnet.VERB,\n",
    "              \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n",
    "\n",
    "def lemma_stop(str):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # sentence=arr[0][4]\n",
    "    tokenizer=RegexpTokenizer('\\w+|\\$]\\d\\[+|\\S+,-')\n",
    "    tokenized = tokenizer.tokenize(str)\n",
    "    lemmatized=[lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in tokenized]\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    filtered_sentence=[w for w in lemmatized if w.lower() not in stop_words]\n",
    "    after_lemma_stop=' '.join(w for w in filtered_sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PvIwQ6ySVHv",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data.npy\n",
    "# data.npy is a 2D array containing the dataset information as\n",
    "# data[i][0] : docID of ith document\n",
    "# data[i][1] : title of ith document\n",
    "# data[i][4] : content of ith document\n",
    "\n",
    "data = np.load('data.npy',allow_pickle = True)\n",
    "# sentence = data[0][4]\n",
    "# print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6aQ7ZcPCH4d",
    "outputId": "8fc93dc4-51e3-48ff-fa64-d5bbef5847a9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204135\n"
     ]
    }
   ],
   "source": [
    "# creating a map {index_in_data_npy, docID}\n",
    "\n",
    "# ex. if ith element in data has docID j,\n",
    "# get_docID[i] will return j\n",
    "\n",
    "get_docID = {}\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "for i in range(0, len(data)) :\n",
    "    get_docID[i] = int(data[i][0])\n",
    "    # print(get_docID[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxoEIRA5rJe8",
    "outputId": "439af5f9-653e-4ac9-849b-21f2741aca5f"
   },
   "outputs": [],
   "source": [
    "# f_content=data[161][4]\n",
    "# # docID of the 161st element in data.npy is:\n",
    "# doc161=get_docID[161] \n",
    "\n",
    "# print(f_content)\n",
    "# print()\n",
    "# print(doc161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A59y0hy1rJfA",
    "outputId": "10be2124-11f3-409b-9055-256b75a18868"
   },
   "outputs": [],
   "source": [
    "# final_doc161=lemma_stop(f_content)\n",
    "# print(final_doc161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omCpgFfRrJfE",
    "outputId": "b9844622-561f-41b1-b86c-026821b380d7"
   },
   "outputs": [],
   "source": [
    "# final_doc1=lemma_stop(data[1][4])\n",
    "# print(final_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4YqxUBHrJfI",
    "outputId": "0d71d645-d6ae-4d19-90f2-dfc8d86b443d"
   },
   "outputs": [],
   "source": [
    "# final_doc10=lemma_stop(data[10][4])\n",
    "# print(final_doc10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsbw8tNbrJfL"
   },
   "source": [
    "*Run the following cell once after all pre-processing (removing JSON etc), and store final lemmatized contents of all docs:* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibq9gAauMI5Q"
   },
   "outputs": [],
   "source": [
    "# Run once after all pre-processing \n",
    "\n",
    "\n",
    "# # Tester code\n",
    "# import time\n",
    "\n",
    "# s = time.time()\n",
    "\n",
    "# for i in range(0, len(data)) :\n",
    "#     f_content = data[i][4]\n",
    "#     contents = f_content\n",
    "#     # print(contents)\n",
    "#     final = lemma_stop (contents)\n",
    "# #     print(type(final))\n",
    "#     # print (final)\n",
    "    \n",
    "# print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a temporary smaller dataset\n",
    "\n",
    "subset = []\n",
    "counter = 0\n",
    "for document in data:\n",
    "    subset.append(document)\n",
    "    counter += 1\n",
    "    if counter == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101.15330791473389\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "titles = []\n",
    "contents = []\n",
    "for document in subset:\n",
    "    modifiedContent = lemma_stop(document[4])\n",
    "    modifiedTitle = lemma_stop(document[1])\n",
    "    titles.append(modifiedTitle)\n",
    "    contents.append(modifiedContent)\n",
    "    \n",
    "print(time.time() - start)  # 110.26236414909363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "contents_temp = contents\n",
    "titles_temp = titles\n",
    "for i in range(1000):\n",
    "    for j in range(len(contents[i])):\n",
    "        contents[i][j] = unidecode.unidecode(contents[i][j])\n",
    "    for j in range(len(titles[i])):\n",
    "        titles[i][j] = unidecode.unidecode(titles[i][j])\n",
    "# for document in contents_temp:\n",
    "#     for word in document:\n",
    "#         word = unidecode.unidecode(word)\n",
    "# for title in titles_temp:\n",
    "#     for word in title:\n",
    "#         word = unidecode.unidecode(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr-HGZhDrJfT"
   },
   "outputs": [],
   "source": [
    "import trie\n",
    "\n",
    "# Create map from docID of the document to an object of class Node \n",
    "# (i.e, the corresponding document trie structure)\n",
    "# ex. if the docID of the document is 1, \n",
    "# getReference[1] gives the object which is the trie structure of docID 1\n",
    "\n",
    "getReference = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzx0ASWgrJfW",
    "outputId": "eb9842e7-50f4-460f-d858-08d25c1ba463"
   },
   "outputs": [],
   "source": [
    "# xx\n",
    "# collection = trie.CollectionNode()\n",
    "# doc1 = trie.Node()\n",
    "# get_doc_trie[get_docID[1]]=doc1\n",
    "# for w in final_doc1:\n",
    "#     print (w)\n",
    "#     collection.add_(w, 0, get_docID[1])\n",
    "#     doc1.add(w, 0)\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPCQrSQkrJfa"
   },
   "outputs": [],
   "source": [
    "# xx\n",
    "# doc2 = trie.Node()\n",
    "# get_doc_trie[get_docID[161]]=doc2\n",
    "# for w in final_doc161:\n",
    "#     collection.add_(w, 0, get_docID[161])\n",
    "#     doc2.add(w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFi28zTjrJfd"
   },
   "outputs": [],
   "source": [
    "# xx\n",
    "# doc3 = trie.Node()\n",
    "# get_doc_trie[get_docID[10]]=doc3\n",
    "# for w in final_doc10:\n",
    "#     collection.add_(w, 0, get_docID[10])\n",
    "#     doc3.add(w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentRoot = []\n",
    "collection = trie.CollectionNode()\n",
    "\n",
    "# initializing the root for 1000 documents\n",
    "for i in range(1000):\n",
    "    newDocument = trie.Node()\n",
    "    documentRoot.append(newDocument)\n",
    "    getReference[get_docID[i]] = newDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inside', 'story', 'Google', 'bold', 'bet', 'hardware', 'nationally', 'televise', 'commercial', 'premier', 'last', 'month', 'empty', 'search', 'box', 'sit', 'stark', 'white', 'background', 'slowly', 'morphs', 'become', 'taller', 'skinnier', 'Redbone', 'croons', 'Come', 'get', 'love', 'line', 'take', 'shape', 'outline', 'phone', 'emerges', 'course', 'Pixel', 'new', 'phone', 'make', 'Google', 'metaphor', 'damn', 'near', 'hit', 'face', 'search', 'box', 'define', 'Google', 'Google', 'need', 'something', 'need', 'find', 'come', 'bare', 'search', 'box', 'basic', 'web', 'page', 'result', 'often', 'return', 'Google', 'around', '18', 'year', 'someday', 'perhaps', 'soon', 'well', 'paradigm', 'use', 'internet', 'go', 'supplant', 'ubiquitous', 'box', 'time', 'Google', 'also', 'decide', 'need', 'become', 'hardware', 'company', 'make', 'product', 'instead', 'leave', 'work', 'solely', 'partner', 'Google', 'would', 'trust', 'future', 'company', 'hardware', 'partner', 'two', 'need', 'directly', 'related', 'something', 'go', 'replace', 'search', 'box', 'sure', 'Google', 'want', 'create', 'may', 'Google', 'Assistant', 'company', 'take', 'AI', 'assistant', 'power', 'Google', 'massive', 'cloud', 'infrastructure', 'huge', 'amount', 'data', 'know', 'even', 'best', 'software', 'pointless', 'without', 'compelling', 'hardware', 'run', 'Google', 'would', 'trust', 'future', 'company', 'hardware', 'partner', 'want', 'control', 'entire', 'thing', 'end', 'end', 'today', 'Google', 'unveil', 'entire', 'interconnect', 'hardware', 'ecosystem', 'two', 'phone', 'intelligent', 'speaker', 'VR', 'headset', 'Wi', 'Fi', 'router', 'medium', 'stream', 'dongle', 'important', 'part', 'ecosystem', 'Pixel', 'phone', 'Google', 'Home', 'speaker', 'exist', 'ideal', 'vessel', 'Google', 'Assistant', 'rest', 'product', 'fill', 'Google', 'ecosystem', 'also', 'enhance', 'Google', 'cloud', 'base', 'intelligence', 'make', 'hardware', 'Google', 'pit', 'Apple', 'first', 'time', 'Google', 'phone', 'v', 'iPhone', 'high', 'stake', 'little', 'margin', 'error', 'look', 'like', 'Google', 'decide', 'follow', 'simple', 'dictum', 'want', 'something', 'right', 'Google', 'make', 'lot', 'hardware', 'past', 'tangential', 'Google', 'core', 'mission', 'search', 'disastrous', 'Nexus', 'Q', 'surprisingly', 'successful', 'Chromecast', 'Google', 'product', 'make', 'different', 'division', 'without', 'real', 'central', 'strategy', 'change', 'April', 'year', 'Google', 'hire', 'Motorola', 'veteran', 'Rick', 'Osterloh', 'head', 'hardware', 'Today', 'hardware', 'produce', 'Google', 'run', 'Osterloh', 'division', 'ensures', 'consistent', 'design', 'purpose', 'Looking', 'Google', 'new', 'hardware', 'see', 'cohesion', 'design', 'ever', 'Finally', 'feel', 'like', 'product', 'come', 'company', 'aesthetic', 'rarefy', 'Apple', 'aggressively', 'futuristic', 'Samsung', 'Instead', 'approachable', 'comfortable', 'almost', 'homey', 'like', 'see', 'Room', 'Board', 'catalog', 'Osterloh', 'insists', 'like', 'Google', 'intentional', 'produce', 'move', 'forward', 'challenge', 'work', 'dozen', 'product', 'make', 'terrific', 'Osterloh', 'say', 'lot', 'discipline', 'lot', 'focus', 'mean', 'shutter', 'Project', 'Ara', 'modular', 'smartphone', 'three', 'month', 'announce', 'Osterloh', 'expect', 'company', 'pick', 'modular', 'torch', 'leave', 'ampnbspmoonshots', 'X', 'division', 'Alphabet', 'Google', 'experiment', 'hardware', 'anymore', 'know', 'exactly', 'want', 'Fundamentally', 'believe', 'lot', 'innovation', 'want', 'end', 'require', 'control', 'end', 'end', 'user', 'experience', 'Osterloh', 'say', 'kind', 'sentiment', 'usually', 'hear', 'Apple', 'Google', 'company', 'need', 'absolutely', 'nail', 'Google', 'Assistant', 'experience', 'meant', 'cede', 'iota', 'control', 'partner', 'first', 'iteration', 'need', 'build', 'system', 'actually', 'ran', 'perfectly', 'Osterloh', 'say', 'refer', 'Google', 'Home', 'aim', 'give', 'user', 'best', 'possible', 'experience', 'total', 'control', 'radical', 'shift', 'Google', 'look', 'Nexus', 'program', 'always', 'design', 'kind', 'reference', 'platform', 'hardware', 'manufacturer', 'learn', 'come', 'Android', 'showcased', 'new', 'processor', 'large', 'screen', 'inexpensive', 'design', 'Sales', 'customer', 'always', 'side', 'hustle', 'core', 'business', 'idea', 'show', 'everyone', 'say', 'Brian', 'Rakowski', 'VP', 'product', 'management', 'Android', 'partner', 'phone', 'manufacturing', 'space', 'take', 'built', 'great', 'product', 'top', 'Meanwhile', 'Nexus', 'kind', 'trundle', 'along', 'small', 'scale', 'Nexus', 'phone', 'always', 'built', 'hardware', 'partner', 'usually', 'amount', 'ampnbspmuch', 'refinement', 'iteration', 'hardware', 'partner', 'already', 'make', 'None', 'necessary', 'anymore', 'Nexus', 'program', 'fulfil', 'mission', 'Android', 'manufacturer', 'need', 'Google', 'show', 'way', 'Google', 'currently', 'plan', 'ever', 'make', 'another', 'Nexus', 'device', 'accord', 'spokesperson', 'Hardcore', 'Android', 'fan', 'may', 'know', 'HTC', 'Original', 'Device', 'Manufacturer', 'Pixel', 'Google', 'say', 'phone', 'base', 'HTC', 'phone', 'seller', 'record', 'phone', 'Google', 'word', 'trundle', 'along', 'Nexus', 'become', 'unnecessary', 'Google', 'found', 'urgent', 'need', 'take', 'Apple', 'head', 'position', 'Android', 'iPhone', 'competitor', 'term', 'sale', 'quality', 'customer', 'service', 'Enter', 'Pixel', 'Google', 'design', 'Pixel', 'hardware', 'find', 'circular', 'G', 'logo', 'back', 'phone', 'also', 'form', 'direct', 'partnership', 'retailer', 'carrier', 'Verizon', 'presume', 'company', 'exclusive', 'US', 'partner', 'though', 'Google', 'sell', 'unlocked', 'version', 'phone', 'store', 'complete', 'optional', 'financing', 'Preorders', 'begin', 'October', '4th', 'begin', 'shipping', 'October', '20th', 'order', 'truly', 'compete', 'Apple', 'Google', 'step', 'customer', 'support', 'game', 'something', 'go', 'wrong', 'iPhone', 'go', 'Apple', 'Store', 'need', 'help', 'Pixel', 'open', 'setting', 'hit', 'support', 'tab', 'Google', 'run', '24', 'hour', 'chat', 'phone', 'support', 'service', 'call', 'opt', 'show', 'rep', 'screen', 'walk', 'whatever', 'go', 'wrong', 'Design', 'wise', 'deny', 'iPhone', 'influence', 'difference', 'course', 'bezel', 'back', 'angle', 'instead', 'curve', 'fingerprint', 'sensor', 'back', 'inside', 'square', 'glass', 'shade', 'help', 'align', 'phone', 'hand', 'phone', 'also', 'slightly', 'thicker', 'top', 'bottom', 'fit', 'camera', 'without', 'require', 'camera', 'bump', 'actually', 'whole', 'bunch', 'thing', 'make', 'sure', 'look', 'much', 'like', 'iPhone', 'Rakowski', 'say', 'distance', 'case', 'similarity', 'unmistakable', 'pricing', 'Pixel', 'fit', 'high', 'end', 'Android', 'market', 'precisely', 'Samsung', 'explode', 'Note', '7', 'left', 'hole', 'Make', 'mistake', 'high', 'end', 'Pixel', 'life', 'start', '649', '32GB', 'Pixel', 'go', '869', 'large', '128GB', 'Pixel', 'XL', 'likely', 'give', 'people', 'use', 'Nexus', 'pricing', 'sticker', 'shock', 'line', 'Apple', 'Samsung', 'phone', 'component', 'Pixel', 'expensive', 'Osterloh', 'admits', 'therefore', 'phone', 'want', 'compromise', 'user', 'experience', 'Osterloh', 'say', 'go', 'premium', 'end', 'Osterloh', 'know', 'certainly', 'go', 'enormous', 'volume', 'product', 'first', 'inning', 'u', 'Google', 'metric', 'success', 'Pixel', 'whether', 'pick', 'significant', 'market', 'share', 'whether', 'garner', 'customer', 'satisfaction', 'form', 'retail', 'carrier', 'partnership', 'Google', 'leverage', 'year', 'come', 'phone', 'feel', 'premium', 'Google', 'lot', 'work', 'banish', 'bugbear', 'vexed', 'Android', 'user', 'year', '12', 'megapixel', 'camera', 'fast', 'Google', 'claim', 'great', 'low', 'light', 'get', 'DxOMark', 'camera', 'score', '89', 'best', 'score', 'ever', 'give', 'phone', 'Though', 'optical', 'image', 'stabilization', 'Google', 'tie', 'camera', 'gyroscope', 'eliminate', 'hand', 'shake', 'jelly', 'effect', 'video', 'new', 'Snapdragon', '821', 'processor', '4', 'gig', 'RAM', 'camera', 'us', 'laser', 'phase', 'detection', 'focus', 'every', 'photo', 'video', 'take', 'get', 'save', 'Google', 'cloud', 'free', 'full', 'resolution', 'life', 'Google', 'also', 'finally', 'rework', 'system', 'behind', 'touch', 'responsiveness', 'display', 'Dave', 'Burke', 'VP', 'engineering', 'Android', 'say', 'touch', 'latency', 'Pixel', 'best', 'Android', 'device', 'ever', 'produce', 'put', 'high', 'speed', 'camera', 'par', 'iPhone', 'still', 'feel', 'little', 'different', 'mainly', 'Android', 'handle', 'inertia', 'little', 'differently', 'iOS', 'Details', 'like', 'latency', 'precisely', 'kind', 'thing', 'get', 'well', 'control', 'end', 'end', 'experience', 'Google', 'new', 'opinionated', 'approach', 'really', 'come', 'fore', 'software', 'Pixel', 'first', 'phone', 'support', 'new', 'Pixel', 'home', 'screen', 'Daydream', 'virtual', 'reality', 'Google', 'Assistant', 'Google', 'Assistant', 'succeed', 'become', 'next', 'interface', 'computer', 'internet', 'Hell', 'division', 'thing', 'might', 'even', 'begin', 'blur', 'abstract', 'underneath', 'helpful', 'conversation', 'capable', 'bot', 'Scott', 'Huffman', 'VP', 'engineering', 'Google', 'Assistant', 'Assistant', 'important', 'potential', 'change', 'paradigm', 'compute', 'input', 'output', 'conversation', 'conversation', 'ultimate', 'interface', 'everyone', 'three', 'year', 'old', 'Huffman', 'say', 'Google', 'Assistant', 'name', 'like', 'Siri', 'Cortana', 'Alexa', 'Huffman', 'patiently', 'answer', 'question', 'way', 'since', 'software', 'unveiled', 'back', 'May', 'felt', 'like', 'name', 'Suzy', 'Johnny', 'something', 'would', 'narrow', 'explains', 'would', 'feel', 'like', 'yet', 'another', 'thing', 'alongside', 'thing', 'oppose', 'meant', 'really', 'overlay', 'across', 'everything', 'decide', 'go', 'Google', 'Assistant', 'feel', 'like', 'represent', 'everything', 'Google', 'Google', 'Huffman', 'say', 'already', 'see', 'Assistant', 'Allo', 'less', 'useful', 'hop', 'Huffman', 'show', 'Nexus', '6P', 'customize', 'run', 'come', 'Nexus', 'phone', 'anytime', 'soon', 'Assistant', 'many', 'way', 'much', 'different', 'voice', 'search', 'Android', 'phone', 'hold', 'home', 'button', 'ask', 'question', 'window', 'slide', 'bottom', 'answer', 'ask', 'next', 'question', 'Like', 'Siri', 'speak', 'Assistant', 'type', 'Unlike', 'Siri', 'Google', 'Assistant', 'surprisingly', 'intelligent', 'understand', 'context', 'ask', 'reading', 'screen', 'answer', 'question', 'reading', 'back', 'key', 'section', 'web', 'page', 'ask', 'something', 'specific', 'might', 'app', 'like', 'show', 'Beyonce', 'Instagram', 'open', 'Instagram', 'take', 'account', 'Assistant', 'really', 'get', 'interest', 'Google', 'Home', 'Google', 'Home', 'consists', 'little', 'speaker', 'put', 'home', 'listens', 'say', 'OK', 'Google', 'answer', 'question', 'Google', 'insists', 'Home', 'send', 'anything', 'say', 'Google', 'hears', 'keyword', 'many', 'way', 'Home', 'big', 'bet', 'Pixel', 'enters', 'sparser', 'competitive', 'field', 'real', 'competition', 'Amazon', 'Echo', 'compare', 'Echo', 'Google', 'Home', 'lot', 'advantage', 'cheaper', '129', 'seem', 'high', 'quality', 'set', 'speaker', 'inside', 'also', 'small', 'cuter', 'swap', 'speaker', 'base', 'new', 'one', 'well', 'match', 'decor', 'run', 'joke', 'Home', 'look', 'like', 'big', 'air', 'freshener', 'take', 'opportunity', 'needle', 'Rishi', 'Chandra', 'VP', 'product', 'management', 'home', 'product', 'comparison', 'actually', 'offend', 'Chandra', 'say', 'Air', 'freshener', 'say', 'consumer', 'good', 'product', 'explicitly', 'design', 'actually', 'put', 'open', 'inside', 'home', 'Google', 'Home', 'really', 'set', 'Home', 'apart', 'Google', 'smart', 'Home', 'two', 'microphone', 'compare', 'Echo', 'seven', 'Chandra', 'claim', 'even', 'well', 'job', 'locate', 'understand', 'question', 'Google', 'us', 'process', 'Chandra', 'call', 'neural', 'beam', 'form', 'take', 'advantage', 'compute', 'cloud', 'identify', 'process', 'speech', 'Google', 'simulated', 'hundred', 'thousand', 'different', 'environment', 'noisy', 'environment', 'quiet', 'environment', 'apply', 'machine', 'learn', 'Chandra', 'say', 'put', 'multiple', 'Homes', 'house', 'closest', 'one', 'respond', 'heck', 'Android', 'phone', 'watch', 'multiple', 'Homes', 'Google', 'say', 'single', 'best', 'device', 'listen', 'time', 'finish', 'request', 'stop', 'others', 'respond', 'Home', 'two', 'microphone', 'compare', 'Echo', 'sevenOn', 'Home', 'Assistant', 'really', 'show', 'far', 'ahead', 'Google', 'compare', 'Alexa', 'Siri', 'ask', 'Play', 'one', 'song', 'Frozen', 'one', 'song', 'play', 'YouTube', 'ask', 'day', 'look', 'like', 'tell', 'calendar', 'list', 'reminder', 'weather', 'news', 'ask', 'play', 'YouTube', 'video', 'TV', 'command', 'Chromecast', 'begin', 'play', 'Google', 'say', 'support', 'video', 'stream', 'service', 'come', 'Chandra', 'ask', 'Home', 'defrost', 'chicken', 'Home', 'found', 'relevant', 'website', 'read', 'back', 'relevant', 'text', 'launch', 'Home', 'work', 'service', 'YouTube', 'Spotify', 'Google', 'Play', 'Music', 'Pandora', 'iHeart', 'Radio', 'Nest', 'Philips', 'Hue', 'SmartThings', 'set', 'default', 'Google', 'Home', 'app', 'also', 'control', 'Chromecasts', 'third', 'party', 'developer', 'directly', 'get', 'platform', 'way', 'Alexa', 'yet', 'Home', 'mostly', 'life', 'Google', 'world', 'annoyingly', 'within', 'one', 'Google', 'account', 'time', 'Huffman', 'promise', 'Google', 'open', 'third', 'party', 'developer', 'later', 'year', 'Echo', 'least', 'month', 'significant', 'competitive', 'advantage', 'Alongside', 'Pixel', 'phone', 'Google', 'Home', 'get', 'first', 'look', 'device', 'fill', 'Google', 'entire', 'ecosystem', 'Daydream', 'VR', 'headset', 'new', 'Chromecast', 'Google', 'Wifi', 'home', 'router', 'Daydream', 'launch', 'early', 'November', 'get', 'first', 'real', 'demo', 'Google', 'hardware', 'event', 'exclusive', 'Pixel', 'short', 'time', 'certainly', 'approachable', 'VR', 'headset', 'Made', 'fabric', 'design', 'make', 'fast', 'simple', 'use', 'easy', 'figure', 'Galaxy', 'Gear', 'though', 'course', 'powerful', 'HTC', 'Vive', 'read', 'much', 'Daydream', 'ampnbsphere', 'Chromecast', 'Ultra', 'support', '4K', 'HDR', 'even', 'let', 'use', 'Ethernet', 'connection', 'connect', 'Assistant', 'insofar', 'stand', 'ready', 'wait', 'Home', 'sling', 'video', 'Google', 'building', 'routerGoogle', 'Wifi', 'also', 'tangentially', 'related', 'Assistant', 'Google', 'figure', 'people', 'need', 'good', 'Wi', 'Fi', 'talk', 'make', 'new', 'router', 'start', '129', 'like', 'Google', 'try', 'work', 'partner', 'Nexus', 'decide', 'make', 'phone', 'Google', 'building', 'router', 'Like', 'Eero', 'design', 'use', 'mesh', 'network', 'buy', 'three', 'pack', '299', 'add', 'many', 'like', 'Like', 'Google', 'Home', 'design', 'inoffensive', 'gadget', 'mind', 'scatter', 'around', 'house', 'like', 'microphone', 'Google', 'Home', 'Google', 'Wifi', 'take', 'advantage', 'Google', 'machine', 'learn', 'well', 'manage', 'device', 'network', 'example', 'typical', 'mesh', 'network', 'wander', 'back', 'bedroom', 'phone', 'might', 'realize', 'much', 'strong', 'access', 'point', 'could', 'connect', 'Instead', 'stay', 'connect', 'one', 'far', 'away', 'phone', 'fault', 'though', 'Chandra', 'point', 'iPhones', 'well', 'router', 'could', 'well', 'job', 'make', 'device', 'switch', 'Wifi', 'Chandra', 'say', 'router', 'communicate', 'one', 'closer', 'likely', 'offer', 'well', 'access', 'point', 'target', '150', 'millisecond', 'transition', 'time', 'Chandra', 'say', 'video', 'chat', 'walk', 'way', 'never', 'see', 'drop', 'Google', 'new', 'batch', 'hardware', 'look', 'like', 'begin', 'coherent', 'ecosystem', 'product', 'come', 'party', 'u', 'without', 'doubt', 'Osterloh', 'say', 'Instead', 'experiment', 'reference', 'Google', 'want', 'sell', 'good', 'large', 'number', 'new', 'Google', 'put', 'different', 'category', 'competition', 'adversary', 'like', 'Apple', 'Microsoft', 'manufacturing', 'partner', 'Even', 'though', 'Google', 'make', 'hardware', 'completely', 'abandon', 'partner', 'ampnbspwill', 'still', 'share', 'software', 'cloud', 'intelligence', 'developed', 'company', 'like', 'Samsung', 'LG', 'make', 'compatible', 'phone', 'speaker', 'router', 'time', 'Google', 'step', 'sale', 'fray', 'like', 'compete', 'partner', 'directly', 'longer', 'go', 'shy', 'think', 'right', 'answer', 'u', 'Chandra', 'say', 'go', 'give', 'OEM', 'ecosystem', 'chance', 'compete', 'meaning', 'fair', 'play', 'field', 'focus', 'absolutely', 'try', 'drive', 'people', 'Android', 'ecosystem', 'Historically', 'kind', 'direct', 'competition', 'software', 'maker', 'hardware', 'company', 'seem', 'like', 'recipe', 'conflict', 'seem', 'hurt', 'Microsoft', 'much', 'Surface', 'line', 'Google', 'seem', 'worried', 'partner', 'unhappy', 'compete', 'Google', 'certainly', 'might', 'happen', 'byproduct', 'focus', 'absolutely', 'try', 'drive', 'people', 'Android', 'ecosystem', 'Osterloh', 'say', 'especially', 'premium', 'tier', 'new', 'playbook', 'Google', 'make', 'first', 'version', 'hardware', 'vertically', 'integrate', 'software', 'hardware', 'create', 'best', 'possible', 'experience', 'product', 'sit', 'high', 'end', 'market', 'eventually', 'distribute', 'software', 'downstream', 'manufacturer', 'work', 'way', 'figure', 'seem', 'try', 'Chandra', 'say', 'Google', 'CEO', 'Sundar', 'Pichai', 'challenged', 'team', 'Let', 'go', 'prove', 'go', 'prove', 'bet', 'company', 'go', 'make', 'bet', 'twofold', 'hardware', 'Assistant', 'Neither', 'proven', 'yet', 'two', 'help', 'think', 'Assistant', 'significant', 'gamble', 'Assistant', 'future', 'mean', 'Google', 'Huffman', 'say', 'think', 'Assistant', 'least', 'one', 'thing', 'potential', 'Google', 'becomes']\n"
     ]
    }
   ],
   "source": [
    "# import unidecode\n",
    "# for i in range(len(contents[26])):\n",
    "#     contents[26][i] = unidecode.unidecode(contents[26][i])\n",
    "# print(contents[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:39<00:00, 25.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.19705152511597\n"
     ]
    }
   ],
   "source": [
    "# creating the documents\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "for i in tqdm(range(1000)):\n",
    "    for w in contents_temp[i]:\n",
    "        collection.add_(w, 0, get_docID[i])\n",
    "        documentRoot[i].add(w, 0)\n",
    "\n",
    "print(time.time() - start)  #39.19705152511597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.getsizeof(documentRoot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go9w6bB9rJfg",
    "outputId": "2e5b7bc8-2e68-4de8-f81d-a142a989c902"
   },
   "outputs": [],
   "source": [
    "query = \"AlphaGo recently changed its policy, aimed at giving more human touch to online interactions on social networking sites. However, this led to complaints that the privacy of users was being compromised.\"\n",
    "final_query = lemma_stop(query)\n",
    "print(final_query)\n",
    "print(len(final_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4Kqgk9hrJfj",
    "outputId": "04bfaa8a-8053-4ab7-e55a-cee2d47edb6f"
   },
   "outputs": [],
   "source": [
    "\n",
    "tf_query = {}\n",
    "for w in final_query:\n",
    "    if w not in tf_query:\n",
    "        tf_query[w] = 1\n",
    "    else:\n",
    "        tf_query[w] += 1\n",
    "        \n",
    "    # Test code just to see distribution of query terms in the documents\n",
    "    \n",
    "    print(w)\n",
    "    df = len(collection.get_doc_list(w,0))\n",
    "    print(collection.get_doc_list(w,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dYc0AfgrJfm",
    "outputId": "54f23ec3-06e0-41d9-c821-6685b861d395"
   },
   "outputs": [],
   "source": [
    "print(len(tf_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBHDg-lJrJfo"
   },
   "source": [
    "***Ranked Retrieval based on TF-IDF Score :***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfT-kdUqrJfp",
    "outputId": "3c95efd0-76c9-4dfe-e425-e79c089931ee",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scores[i] stores the dot product of the tf-idf score vectors of the query and document of docID i in the corpus\n",
    "scores={}\n",
    "\n",
    "# length[i] stores the length of the tf-idf score vector for document of docID i in the corpus\n",
    "length={}\n",
    "\n",
    "# N is the total number of documents in the corpus\n",
    "N=3\n",
    "\n",
    "import math\n",
    "\n",
    "for query_term in tf_query:\n",
    "    \n",
    "    docs_having_query_term = collection.get_doc_list(query_term,0)\n",
    "    df = len(docs_having_query_term)\n",
    "    \n",
    "    print('-------------------------------------')\n",
    "    print('Term in query=', query_term)\n",
    "    print('List of documents with this term=', docs_having_query_term)\n",
    "    print()\n",
    "    \n",
    "    if df==0:\n",
    "        idf=0\n",
    "    else:\n",
    "        idf=math.log10(N/df)\n",
    "        \n",
    "    print('df=',df)\n",
    "    print('idf=',idf)\n",
    "    \n",
    "    tfidf_query= tf_query[query_term] * idf\n",
    "        \n",
    "    for doc in docs_having_query_term:\n",
    "        \n",
    "        tf_doc = get_doc_trie[doc].count_words(query_term,0)\n",
    "        \n",
    "        print('tf for doc',doc,'is',tf_doc)\n",
    "        \n",
    "        tfidf_doc = tf_doc * idf\n",
    "        \n",
    "        print('tfidf for doc',doc,'is',tfidf_doc)\n",
    "        print()\n",
    "        \n",
    "        if doc not in scores:\n",
    "            scores[doc]=0\n",
    "            length[doc]=0\n",
    "        else:\n",
    "            scores[doc] += (tfidf_query * tfidf_doc)\n",
    "            length[doc] += (tfidf_doc ** 2)\n",
    "        \n",
    "for doc in scores:\n",
    "    \n",
    "    if length[doc] != 0:\n",
    "        print(length[doc])\n",
    "        scores[doc] = scores[doc]/ math.sqrt(length[doc])\n",
    "\n",
    "sorted_scores = sorted(scores.items(), key = lambda kv : kv[1] , reverse = True)\n",
    "\n",
    "maxshow = min(10, len(scores))\n",
    "\n",
    "print('\\n\\n')\n",
    "print('============================================')\n",
    "\n",
    "for i in range(maxshow):\n",
    "    \n",
    "#     print(i)\n",
    "    print()\n",
    "    print('doc ID=', sorted_scores[i][0])\n",
    "    print('tf-idf score=', sorted_scores[i][1])\n",
    "    \n",
    "print('\\n\\n')\n",
    "print('============================================')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WqsqWNnFNOhO"
   },
   "source": [
    "***Original Text :***\n",
    "\n",
    "      We’re back in Dale Cooper’s position, wandering through a freshly revived world, and trying to catch up with the ways it’s moved on in his absence.\n",
    "\n",
    "***Processed Text :***\n",
    "\n",
    "      We back Dale Cooper position wander freshly revive world try catch way move absence"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
