{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__1Nxb4gRIeN"
   },
   "source": [
    "Done so far :\n",
    "\n",
    "\n",
    "*   Lemmatization\n",
    "*   Stop Words Removal\n",
    "\n",
    "Verify :\n",
    "\n",
    "* Normalization - removing accents, etc.\n",
    "* Dates replaced with strings\n",
    "* Case-folding\n",
    "* Removed HTML entity codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qZ-TMc9SVHl"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import wordninja \n",
    "\n",
    "####### After importing nltk, run the following only once ######\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "### pip install wordninja ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_htmlcodes(document):\n",
    "    \n",
    "    replacement = {\n",
    "                    \"&ampnbsp\": ' ',\n",
    "                    \"&ampamp\": '&',\n",
    "                    \"&ampquot\": '\\'',\n",
    "                    \"&ampldquo\": '\\\"',\n",
    "                    \"&amprdquo\": '\\\"',\n",
    "                    \"&amplsquo\": '\\'',\n",
    "                    \"&amprsquo\": '\\'',\n",
    "                    \"&amphellip\": '...',\n",
    "                    \"&ampndash\": '-',\n",
    "                    \"&ampmdash\": '-'\n",
    "                  }\n",
    "    \n",
    "    for str in replacement:\n",
    "        document = document.replace(str, replacement[str])\n",
    "        \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LpQkEVQOSVHr"
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \n",
    "    tag=nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict={\"J\": wordnet.ADJ, \n",
    "              \"N\": wordnet.NOUN,\n",
    "              \"V\": wordnet.VERB,\n",
    "              \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n",
    "\n",
    "def lemma_stop(str):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenizer = RegexpTokenizer('\\w+|\\$]\\d\\[+|\\S+,-')\n",
    "    tokenized = tokenizer.tokenize(str)\n",
    "    lemmatized = [lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in tokenized]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in lemmatized if w.lower() not in stop_words]\n",
    "    after_lemma_stop = ' '.join(w for w in filtered_sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_credible (text):\n",
    "    \n",
    "    match = re.search(r'[!@#?&{}()]', text)\n",
    "    \n",
    "    if match:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_words(text):\n",
    "    \n",
    "    text = re.sub('[!@#?&{}()]', '', text)\n",
    "    text=re.sub(r'[^\\x00-\\x7F]',\" \",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document (document_string):\n",
    "    \n",
    "    cleaned_doc = document_string\n",
    "    for word in document_string.split():\n",
    "                if is_not_credible(word):\n",
    "                    temp= scrub_words(word)\n",
    "                    split=wordninja.split(temp)\n",
    "                    if len(split)>7:\n",
    "                          cleaned_doc = cleaned_doc.replace(word,'')\n",
    "                    else:\n",
    "                        replace_with=' '.join(word for word in split)\n",
    "                        cleaned_doc = cleaned_doc.replace(word, replace_with)\n",
    "    return cleaned_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "count_dates = []\n",
    "\n",
    "def replace_dates(documentString, docID):\n",
    "    \n",
    "    regEx = '(([0-9]+(/)[0-9]+(/)[0-9]+)|([0-9]+(/)[0-9]+))'\n",
    "    iterator = re.finditer(regEx, documentString)\n",
    "    listOfDates = [(m.start(0), m.end(0)) for m in iterator]\n",
    "    tmp = []\n",
    "    replace_with = []\n",
    "    for indices in listOfDates:\n",
    "        date = documentString[indices[0]:indices[1]]\n",
    "        tmp.append(date)\n",
    "        count = date.count('/')\n",
    "        newDate = ''\n",
    "        if count == 2:\n",
    "            check_year = date[-3]\n",
    "            \n",
    "            if check_year == '/':\n",
    "                YY = date[-2:]\n",
    "                \n",
    "                if int(YY) <= 19:\n",
    "                    proper_date = date[:-2] + '20' + YY\n",
    "                    date = date.replace(date,proper_date)\n",
    "                else:\n",
    "                    proper_date = date[:-2] + '19' + YY\n",
    "                    date = date.replace(YY,('19'+YY))\n",
    "                    \n",
    "            try:\n",
    "                newDate = datetime.strptime(date, '%m/%d/%Y').strftime('%d %b %Y')\n",
    "            except ValueError as ve:\n",
    "                newDate = date\n",
    "        else:\n",
    "            try:\n",
    "                newDate = datetime.strptime(date, '%m/%d').strftime('%d %b')\n",
    "            except ValueError as ve:\n",
    "                newDate = date\n",
    "                \n",
    "        count_dates.append([docID, date])\n",
    "        newDate = newDate.replace(' ', '')\n",
    "        replace_with.append(newDate)\n",
    "        \n",
    "    for i in range(len(tmp)):\n",
    "        documentString = documentString.replace(tmp[i], replace_with[i])\n",
    "    \n",
    "    return documentString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr-HGZhDrJfT"
   },
   "outputs": [],
   "source": [
    "# reading persistent files\n",
    "\n",
    "import pickle\n",
    "import trie\n",
    "\n",
    "get_docID = {}\n",
    "get_index = {}\n",
    "\n",
    "data = np.load(\"mod_data.npy\", allow_pickle = True)\n",
    "\n",
    "for i in range(0, len(data)) :\n",
    "    get_docID[i] = int(data[i][0])\n",
    "    get_index[int(data[i][0])] = i\n",
    "    \n",
    "collection = None\n",
    "documentRoot = {}\n",
    "max_tf = {}\n",
    "\n",
    "with open('collection.pickle', 'rb') as handle:\n",
    "    collection = pickle.load(handle)\n",
    "with open('documentRoot.pickle', 'rb') as handle:\n",
    "    documentRoot = pickle.load(handle)\n",
    "with open('max_tf.pickle', 'rb') as handle:\n",
    "    max_tf = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go9w6bB9rJfg",
    "outputId": "2e5b7bc8-2e68-4de8-f81d-a142a989c902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trump', 'putin']\n"
     ]
    }
   ],
   "source": [
    "# processing query\n",
    "\n",
    "import unidecode\n",
    "\n",
    "query = 'trump and putin'\n",
    "final_query = replace_dates(query, -1)\n",
    "final_query = lemma_stop(final_query)\n",
    "\n",
    "for i in range(len(final_query)):\n",
    "    final_query[i] = unidecode.unidecode(final_query[i])\n",
    "    # case-folding\n",
    "    final_query[i] = final_query[i].lower()\n",
    "print(final_query)\n",
    "\n",
    "tf_query = {}\n",
    "for w in final_query:\n",
    "    if w not in tf_query:\n",
    "        tf_query[w] = 1\n",
    "    else:\n",
    "        tf_query[w] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBHDg-lJrJfo"
   },
   "source": [
    "***Ranked Retrieval based on TF-IDF Score :***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfT-kdUqrJfp",
    "outputId": "3c95efd0-76c9-4dfe-e425-e79c089931ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Term in query =  trump\n",
      "\n",
      "df =  502\n",
      "idf =  2.308185887804487\n",
      "-------------------------------------\n",
      "Term in query =  putin\n",
      "\n",
      "df =  44\n",
      "idf =  3.3654369284633194\n",
      "\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  130278\n",
      "Keywords:\n",
      "\n",
      "Trump and Putin vow to take on Syria, North Korea together\n",
      "\n",
      "title score =  5.673622816267807\n",
      "putin -2.644271872364037 4\n",
      "trump -2.308185887804487 7\n",
      "\n",
      "\n",
      "President Trump and Russian strongman Vladimir Putin will work together to end the Syrian civil war and stop the suffering in the battle-scarred country, the White House said Tuesday. The pair spoke by phone in their first known conversation since the that sparked new tensions between Washington and Moscow, and the White House said the pair  ... \n",
      "\n",
      "tf-idf score= 187.517972147657\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  128903\n",
      "Keywords:\n",
      "\n",
      "Trump’s Syria airstrike was a huge loss for Putin\n",
      "\n",
      "title score =  5.673622816267807\n",
      "putin -3.3654369284633194 14\n",
      "trump -1.318963364459707 2\n",
      "\n",
      "\n",
      "The biggest loser from on a Syrian air base wasn’t “President” Bashar al-Assad. It was Vladimir Putin. The Syrian leader was punished, but Russia’s new czar was humiliated. Even with an hour’s warning of the attacks, Putin’s military in Syria did nothing to defend its ally. For all of the Russian bluster in recent years, Putin couldn’t stop our strikes. His military lacked the means to  ... \n",
      "\n",
      "tf-idf score= 177.3683464242056\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  128377\n",
      "Keywords:\n",
      "\n",
      "Kremlin says Trump and Putin could mend tense relations\n",
      "\n",
      "title score =  5.673622816267807\n",
      "putin -2.150140259851565 5\n",
      "trump -1.6670231411921297 8\n",
      "\n",
      "\n",
      "WASHINGTON – US-Russia relations , but a meeting between President Trump and President Vladimir Putin could mend divisions, Kremlin spokesman said Sunday​. “I think if two presidents meet each other, if they exchange views, then there will be a chance for our volatile relations to get better,” Dmitry Peskov Putin previously suggested the meeting could take place in July when Trump travels to Germany  ... \n",
      "\n",
      "tf-idf score= 144.5316194469895\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  129018\n",
      "Keywords:\n",
      "\n",
      "What’s sinking US-Russia relations Team Trump’s truth-telling\n",
      "\n",
      "title score =  2.308185887804487\n",
      "putin -3.1250485764302254 6\n",
      "trump -2.308185887804487 7\n",
      "\n",
      "\n",
      "Vladimir Putin and President Trump are both right: US-Russian relations have “been degraded,” as Putin put it Wednesday. Indeed, Trump said they may be “at an all-time low.” But most interesting is the reason for the freeze. Years of Russia and its allies, Iran and Syria, operating with virtual impunity have  ... \n",
      "\n",
      "tf-idf score= 101.97854515847717\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  128135\n",
      "Keywords:\n",
      "\n",
      "Both parties are bungling the Trump-Russia investigation\n",
      "\n",
      "title score =  2.308185887804487\n",
      "putin -3.3654369284633194 7\n",
      "trump -1.9784450466895607 5\n",
      "\n",
      "\n",
      "Right and left, we are disgracing ourselves. The alleged Putin-Trump connections cut to the heart of our republic. Even the faintest possibility that a hostile power infiltrated a presidential campaign and, consequently, an administration, demands a sober, thorough investigation that puts our national interest above party politics. All Americans should demand the truth about this matter. It’s about the  ... \n",
      "\n",
      "tf-idf score= 100.30145264519882\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  128939\n",
      "Keywords:\n",
      "\n",
      "Trump’s team has sent Russia a clear ‘nyet’\n",
      "\n",
      "title score =  2.308185887804487\n",
      "putin -3.178468210215357 8\n",
      "trump -2.051720789159544 7\n",
      "\n",
      "\n",
      "Were you afraid Russia’s Vladimir Putin had elected a Manchurian Candidate to the US presidency who’d do Kremlin’s bidding Fear no more. Until last week, President Trump’s entire time in office was dogged by allegations of colluding with Moscow to . The and various are still investigating those, as they should. But if Putin hoped  ... \n",
      "\n",
      "tf-idf score= 98.16750382688488\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  127364\n",
      "Keywords:\n",
      "\n",
      "The West needs a better Trump-Merkel relationship than this\n",
      "\n",
      "title score =  2.308185887804487\n",
      "putin -2.617562055471471 5\n",
      "trump -2.308185887804487 9\n",
      "\n",
      "\n",
      "... and icy words. That’s bad news. There are four leaders who really matter today, and two are our enemies, Vladimir Putin of Russia and China’s Xi Jinping. We in the West need solidarity between the other two, Angela Merkel, the de facto leader of Europe, and Donald Trump, on whom the weight of global leadership still sits uneasily. Quarrel as we may over lesser issues, the United States and Europe  ... \n",
      "\n",
      "tf-idf score= 92.45332819322694\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  129244\n",
      "Keywords:\n",
      "\n",
      "Donald Trump Jr. wore a ‘very fake news’ shirt and the internet lost it\n",
      "\n",
      "title score =  2.308185887804487\n",
      "putin -2.5240776963474896 1\n",
      "trump -2.308185887804487 2\n",
      "\n",
      "\n",
      "... a top that reads “if my dad wasn’t rich I’d be screwed.” Another edit , now starring a shirtless Vladimir Putin with angel wings, adorned with the word “besties.”  ... \n",
      "\n",
      "tf-idf score= 90.6986829627861\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  128511\n",
      "Keywords:\n",
      "\n",
      "Deadly chemical attack shows US can’t trust Assad — or Putin\n",
      "\n",
      "title score =  3.3654369284633194\n",
      "putin -2.0192621570779914 2\n",
      "trump -1.615730121463141 4\n",
      "\n",
      "\n",
      "... So we didn’t bomb even one remote Syrian sandhill. Instead, Obama fell for an attractive offer by Russian President Vladimir Putin: Syria would join the international chemical-banning convention and, with United Nations oversight and American financing, it would rid itself of all chemical stockpiles and the means to weaponize them. Although chemical warfare was cardinal to Syria’s defense doctrine, Obama bought into Assad’s sincerity: A UN-led operation, he believed, would  ... \n",
      "\n",
      "tf-idf score= 90.03091646284035\n",
      "\n",
      "\n",
      "============================================\n",
      "\n",
      "doc ID =  130421\n",
      "Keywords:\n",
      "\n",
      "Bad news for the Trump-Russia tinfoil-hat brigade\n",
      "\n",
      "title score =  2.308185887804487\n",
      "trump -2.308185887804487 19\n",
      "putin -2.3026673721064816 7\n",
      "\n",
      "\n",
      "During a Capitol Hill hearing this week over his investigation into allegations President Trump worked with the Kremlin to steal the election, FBI Director James Comey showed his hand, and he’s not holding any aces. In fact, he’s got a whole lot of nothing. In an exchange with Democratic Sen. Al Franken, Comey revealed the assumptions undergirding his investigation, which started in the  ... \n",
      "\n",
      "tf-idf score= 86.54294425911044\n",
      "\n",
      "\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "\n",
    "# scores[i] stores the dot product of the tf-idf score vectors of the query and document of docID i in the corpus\n",
    "scores = {}\n",
    "title_score = {}\n",
    "\n",
    "# N is the total number of documents in the corpus\n",
    "N = len(documentRoot)\n",
    "\n",
    "# wordsInDoc[i] is a sorted list of (word, score) tuples where\n",
    "# score is the tf-idf score for the (word, <ith doc>) pair\n",
    "wordsInDoc = {}\n",
    "\n",
    "factor = {}\n",
    "\n",
    "import math\n",
    "import bisect\n",
    "\n",
    "for query_term in tf_query:\n",
    "    \n",
    "    docs_having_query_term = collection.get_doc_list(query_term, 0)\n",
    "    df = len(docs_having_query_term)\n",
    "    idf = 0\n",
    "    \n",
    "    print('-------------------------------------')\n",
    "    print('Term in query = ', query_term)\n",
    "    print()\n",
    "    \n",
    "    if df == 0:\n",
    "        idf = 0\n",
    "    else:\n",
    "        idf = math.log10(N/df)\n",
    "        \n",
    "    docs_having_query_term_in_title = collection.get_title_list(query_term,0)\n",
    "    \n",
    "    for docID in docs_having_query_term_in_title:\n",
    "        if docID in title_score:\n",
    "            title_score[docID] += idf\n",
    "        else:\n",
    "            title_score[docID] = idf\n",
    "        \n",
    "    print('df = ',df)\n",
    "    print('idf = ',idf)\n",
    "    \n",
    "    tfidf_query = tf_query[query_term] * idf\n",
    "        \n",
    "    for docID in docs_having_query_term:\n",
    "        \n",
    "        tf_doc = documentRoot[docID].count_words(query_term, 0)\n",
    "        tf_doc = 0.5 + 0.5*tf_doc/max_tf[docID]\n",
    "        tfidf_doc = (tf_doc)\n",
    "        \n",
    "        if docID not in scores:\n",
    "            scores[docID] = (tfidf_query * tfidf_doc)\n",
    "            wordsInDoc[docID] = []\n",
    "            bisect.insort(wordsInDoc[docID], [-tfidf_query * tfidf_doc, query_term])\n",
    "            factor[docID] = idf\n",
    "        else:\n",
    "            scores[docID] += (tfidf_query * tfidf_doc)\n",
    "            bisect.insort(wordsInDoc[docID], [-tfidf_query * tfidf_doc, query_term])\n",
    "            factor[docID] += idf\n",
    "            \n",
    "# print(title_score)\n",
    "\n",
    "for docID in scores:\n",
    "    \n",
    "    #if documentLength[docID] != 0:\n",
    "    scores[docID] *= factor[docID]\n",
    "    if docID in title_score:\n",
    "        scores[docID] *= 1 + title_score[docID]\n",
    "\n",
    "sorted_scores = sorted(scores.items(), key = lambda kv : kv[1] , reverse = True)\n",
    "\n",
    "maxshow = min(10, len(scores))\n",
    "\n",
    "print('\\n\\n')\n",
    "print('============================================')\n",
    "\n",
    "for i in range(maxshow):\n",
    "    \n",
    "    print()\n",
    "    docID = sorted_scores[i][0]\n",
    "    print('doc ID = ', docID)\n",
    "    cnt = 0\n",
    "    print('Keywords:')\n",
    "    print()\n",
    "    print(data[get_index[sorted_scores[i][0]]][1])\n",
    "    print()\n",
    "    if sorted_scores[i][0] not in title_score:\n",
    "        print('title score = ',0)\n",
    "    else:\n",
    "        print('title score = ',title_score[sorted_scores[i][0]])\n",
    "    for j in range(len(wordsInDoc[docID])):\n",
    "        print(wordsInDoc[docID][j][1], wordsInDoc[docID][j][0], end = ' ')\n",
    "        print(documentRoot[docID].count_words(wordsInDoc[docID][j][1], 0))\n",
    "    print()\n",
    "    print()\n",
    "    count = 0\n",
    "    found = 0\n",
    "    words_before=queue.Queue()\n",
    "    at_start = 1\n",
    "    display = \"\"\n",
    "    \n",
    "    for word in data[get_index[docID]][4].split():\n",
    "            \n",
    "        check_with=replace_dates(word, -1)\n",
    "        check_with = check_with.lower()\n",
    "        if len(lemma_stop(check_with)) > 0:\n",
    "            check_with=lemma_stop(check_with)[0]\n",
    "        else:\n",
    "            check_with=word\n",
    "        \n",
    "        if check_with == wordsInDoc[docID][0][1]:\n",
    "            found=1\n",
    "            \n",
    "        if found == 1:\n",
    "            display = display + word + \" \"\n",
    "            count += 1\n",
    "            if count == 50:\n",
    "                break\n",
    "        if found == 0:\n",
    "            words_before.put(word)\n",
    "            if words_before.qsize()>20:\n",
    "                remove=words_before.get()\n",
    "                at_start=0\n",
    "                \n",
    "    if not at_start:\n",
    "        print('...', end = ' ')\n",
    "    while words_before.qsize() > 0:\n",
    "        print(words_before.get(), end = ' ')\n",
    "    print(display, end = ' ')\n",
    "    print('...', end = ' ')\n",
    "    print('\\n')\n",
    "    print('tf-idf score=', sorted_scores[i][1])\n",
    "    print('\\n')\n",
    "    print('============================================')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
